{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Theoretical part 1**"
      ],
      "metadata": {
        "id": "1TTHhpdVWN31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_eaOof4fEyhK"
      },
      "outputs": [],
      "source": [
        "# What is a Decision Tree, and how does it work?\n",
        "# Answer:\n",
        "# Definition: A Decision Tree is a supervised machine learning algorithm used for both classification and regression tasks. It models decisions and their possible consequences in a tree-like structure, where internal nodes represent decisions based on features, branches represent decision outcomes, and leaf nodes represent final predictions (class labels for classification or continuous values for regression).\n",
        "# How It Works:\n",
        "# Root Node: The process starts at the root node, which contains the entire dataset. A feature is selected to split the data based on a criterion (e.g., Gini Impurity, Entropy).\n",
        "# Splitting: The dataset is split into subsets based on the feature value (e.g., if a feature is numerical, a threshold is chosen; if categorical, each category may form a branch). The goal is to create subsets that are as pure as possible (i.e., containing instances of a single class or similar values).\n",
        "# Internal Nodes: Each internal node represents a decision based on a feature, and the process repeats recursively on each subset, selecting the best feature to split at each step.\n",
        "# Leaf Nodes: The recursion stops when a stopping criterion is met (e.g., maximum depth, minimum samples per node, or pure subsets). The leaf nodes provide the final predictions.\n",
        "# Prediction: For a new data point, the algorithm traverses the tree from the root to a leaf node by following the decision rules, and the prediction is the value (class or continuous) at the leaf node.\n",
        "# Key Characteristics:\n",
        "# Decision Trees are interpretable, as the tree structure can be visualized and understood.\n",
        "# They are non-parametric, meaning they do not assume any specific distribution of the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. What are impurity measures in Decision Trees?\n",
        "# Answer:\n",
        "# Definition: Impurity measures are metrics used to quantify the \"impurity\" or \"disorder\" of a dataset at a node in a Decision Tree. They help determine how well a split separates the data into homogeneous subsets (e.g., subsets containing instances of a single class in classification).\n",
        "# Purpose: The goal of a Decision Tree is to minimize impurity after each split, making the subsets as pure as possible.\n",
        "# Common Impurity Measures:\n",
        "# Gini Impurity: Measures the probability of incorrectly classifying a randomly chosen instance if it were labeled according to the distribution of classes in the subset. Used for classification tasks.\n",
        "# Entropy: Measures the amount of uncertainty or randomness in the data, based on information theory. Used for classification tasks.\n",
        "# Mean Squared Error (MSE) or Variance: Used for regression tasks, where the goal is to minimize the variance within each subset.\n",
        "# Usage: At each node, the algorithm evaluates potential splits and selects the one that results in the largest reduction in impurity (or increase in purity)."
      ],
      "metadata": {
        "id": "p49q9pGuTvQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. What is the mathematical formula for Gini Impurity?\n",
        "\n",
        "# Gini Impurity Formula:\n",
        "\n",
        "# Gini Impurity = 1 - Σ(p_i)^2\n",
        "\n",
        "# where:\n",
        "# p_i is the probability of an instance belonging to class i in the subset.\n",
        "\n",
        "# Example:\n",
        "# Let's say we have a subset with 10 instances, and 4 belong to class A and 6 to class B.\n",
        "# p_A = 4/10 = 0.4\n",
        "# p_B = 6/10 = 0.6\n",
        "\n",
        "# Gini Impurity = 1 - (0.4)^2 - (0.6)^2\n",
        "#              = 1 - 0.16 - 0.36\n",
        "#              = 0.48\n"
      ],
      "metadata": {
        "id": "HR_FeGZYTvTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4.) What is the mathematical formula for Entropy?\n",
        "\n",
        "# Answer:\n",
        "# Definition: Entropy is a measure of uncertainty or randomness in a dataset. In decision trees, it quantifies the impurity of a set of examples.  A lower entropy indicates higher certainty (purity), while higher entropy signifies greater uncertainty (impurity).\n",
        "\n",
        "# Formula:\n",
        "\n",
        "# Entropy(S) = - Σ (pᵢ * log₂(pᵢ))\n",
        "\n",
        "# Where:\n",
        "\n",
        "# S is the set of examples.\n",
        "# pᵢ is the proportion of instances belonging to class i in the set S.\n",
        "# The summation is taken over all classes i.\n",
        "\n",
        "# Interpretation:\n",
        "\n",
        "# Entropy ranges from 0 (completely pure, all examples belong to the same class) to log₂(number of classes) (maximum impurity, examples are evenly distributed across all classes).  For binary classification, the maximum entropy is 1.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y_g6_q8pHv5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.) What is Information Gain, and how is it used in Decision Trees?\n",
        "\n",
        "# Answer:\n",
        "# Definition: Information Gain is a crucial metric in Decision Trees used to quantify the reduction in entropy (or other impurity measures) achieved by splitting a dataset based on a particular feature. It measures how much information about the target variable is gained by knowing the value of a specific feature.\n",
        "\n",
        "# Calculation:\n",
        "# Information Gain(S, A) = Entropy(S) - Σ [(|Sᵥ| / |S|) * Entropy(Sᵥ)]\n",
        "\n",
        "# Where:\n",
        "\n",
        "# S is the original dataset.\n",
        "# A is the feature used to split the data.\n",
        "# Sᵥ is the subset of S for which feature A has value v.\n",
        "# |S| and |Sᵥ| represent the number of instances in S and Sᵥ, respectively.\n",
        "# Entropy(S) and Entropy(Sᵥ) are the entropies of the original dataset and its subsets, respectively.\n",
        "\n",
        "\n",
        "# Usage:\n",
        "\n",
        "# In a Decision Tree, the algorithm calculates Information Gain for each possible feature split at each node. The feature with the highest Information Gain is selected as the splitting criterion because it leads to the greatest reduction in entropy, and thus, the most significant increase in the purity of the subsets.  The process is then repeated recursively on each subset until a stopping criterion is met.\n",
        "\n",
        "# Example:\n",
        "\n",
        "# Let's say you have a dataset about whether to play tennis based on weather conditions (outlook, temperature, humidity, wind). To decide which feature to split on first, the algorithm calculates the Information Gain for each feature (outlook, temperature, humidity, wind). The feature with the highest Information Gain (e.g., outlook) is chosen as the root node, and the data is split into subsets based on the values of outlook (sunny, overcast, rainy). This process continues recursively on the subsets until the tree is complete.\n"
      ],
      "metadata": {
        "id": "sFAZlbP7Rmai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. What is the difference between Gini Impurity and Entropy?\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Both Gini Impurity and Entropy are measures of impurity used in decision trees to determine the best split at each node.  They both aim to quantify the disorder or uncertainty in a dataset, with lower values indicating purer (more homogenous) subsets.  However, they use different mathematical formulations:\n",
        "\n",
        "# Gini Impurity:\n",
        "\n",
        "# * Focuses on the probability of misclassifying a randomly chosen element if it were randomly labeled according to the class distribution in the subset.\n",
        "# * Ranges from 0 (pure node, all instances belong to the same class) to 0.5 (maximum impurity for binary classification, classes are equally distributed).\n",
        "# * Computationally less expensive to calculate than entropy.\n",
        "# * Tends to isolate the dominant class, resulting in somewhat different tree structures compared to entropy.\n",
        "\n",
        "\n",
        "# Entropy:\n",
        "\n",
        "# * Measures the uncertainty or randomness in the dataset based on information theory.  It quantifies the amount of information needed to classify a randomly chosen element from the subset.\n",
        "# * Ranges from 0 (pure node) to log₂(number of classes) (maximum impurity). For binary classification, this is 1.\n",
        "# * More computationally expensive than Gini Impurity.\n",
        "# * More sensitive to changes in class proportions, potentially leading to a different optimal split compared to Gini Impurity.\n",
        "\n",
        "# In practice:\n",
        "\n",
        "# * Gini Impurity and Entropy often lead to similar tree structures, with relatively minor differences in performance.\n",
        "# * Gini Impurity is often preferred due to its computational efficiency.\n",
        "# * The choice between them is often empirical, and might depend on specific dataset characteristics.\n"
      ],
      "metadata": {
        "id": "I8XUjiFMR25e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. What is the mathematical explanation behind Decision Trees?\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Decision Trees, at their core, aim to partition the data into subsets that are as pure as possible with respect to the target variable.  The mathematical foundation lies in information theory and impurity measures.\n",
        "\n",
        "# 1. Impurity Measures (e.g., Gini Impurity, Entropy):\n",
        "\n",
        "# These measures quantify the disorder or heterogeneity within a subset of data.  A pure subset contains only instances of a single class (in classification) or has very low variance (in regression).\n",
        "\n",
        "# * Gini Impurity:  Measures the probability of misclassifying a randomly chosen element if labeled according to the class distribution in the subset.  Mathematically:\n",
        "\n",
        "#   Gini Impurity = 1 - Σ (pᵢ)²\n",
        "\n",
        "#   where pᵢ is the proportion of instances belonging to class i in the subset.\n",
        "\n",
        "# * Entropy:  Measures the uncertainty or randomness in a dataset based on information theory.  Mathematically:\n",
        "\n",
        "#   Entropy = - Σ (pᵢ * log₂(pᵢ))\n",
        "\n",
        "#   where pᵢ is the proportion of instances belonging to class i in the subset.\n",
        "\n",
        "# 2. Information Gain:\n",
        "\n",
        "# The core of the decision-making process in a decision tree is to find the best split at each node.  This is achieved by calculating the Information Gain for each potential split:\n",
        "\n",
        "# Information Gain = Entropy(parent) - Σ [(|child_i| / |parent|) * Entropy(child_i)]\n",
        "\n",
        "# where:\n",
        "#     * Entropy(parent) is the entropy of the parent node.\n",
        "#     * |child_i| is the number of instances in the i-th child node.\n",
        "#     * |parent| is the number of instances in the parent node.\n",
        "#     * Entropy(child_i) is the entropy of the i-th child node.\n",
        "\n",
        "# The feature that maximizes the Information Gain is chosen for the split.  This means the split leads to the greatest reduction in uncertainty (impurity) about the target variable.\n",
        "\n",
        "\n",
        "# 3. Recursive Partitioning:\n",
        "\n",
        "# The process of splitting nodes is repeated recursively, creating a tree structure.  Each internal node represents a test on a feature, and each branch represents an outcome of the test.  The recursive partitioning continues until a stopping criterion is met (e.g., maximum depth of the tree, minimum number of instances in a leaf node, or minimum impurity reduction).  Leaf nodes represent the final predictions.\n",
        "\n",
        "\n",
        "# 4. Prediction:\n",
        "\n",
        "# To make a prediction for a new data point, the algorithm traverses the tree from the root to a leaf node, following the decision rules at each internal node.  The value at the leaf node represents the prediction for the new data point.\n",
        "\n",
        "\n",
        "# In summary, Decision Trees utilize impurity measures and Information Gain to recursively partition the feature space, aiming to create a tree structure that effectively separates different classes or predicts continuous values.  The mathematics ensures that the tree efficiently splits the data into increasingly pure subsets, enabling accurate classification or regression.\n"
      ],
      "metadata": {
        "id": "rRdIq8JHR_gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. What is Pre-Pruning in Decision Trees?\n",
        "\n",
        "# Pre-pruning in decision trees is a technique to prevent overfitting by halting the tree's growth before it perfectly classifies the training data.  It sets limits on the tree's complexity during its construction.  This is in contrast to post-pruning, where the tree is grown fully and then pruned back.\n",
        "\n",
        "\n",
        "# Common pre-pruning methods involve setting constraints such as:\n",
        "\n",
        "\n",
        "# * Maximum depth:  Limits how many levels the tree can have.  A shallower tree is less complex and less prone to overfitting.\n",
        "# * Minimum samples per leaf:  Specifies the minimum number of training samples required in a leaf node.  This prevents the tree from creating overly specific leaf nodes based on a small number of examples.\n",
        "# * Minimum samples per split:  Specifies the minimum number of samples required to split an internal node. This ensures that a split only happens if it's based on a sufficiently large subset of data.\n",
        "# * Maximum number of leaf nodes: Directly limits the number of leaf nodes in the tree.\n",
        "# * Minimum impurity decrease: Requires a minimum reduction in impurity (e.g., Gini impurity or entropy) for a split to be made. This avoids splits that don't significantly improve the model's accuracy.\n",
        "\n",
        "\n",
        "# By imposing these constraints, pre-pruning helps create a more generalized model that performs better on unseen data.\n"
      ],
      "metadata": {
        "id": "wqDMflJZSOTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. What is Post-Pruning in Decision Trees?\n",
        "\n",
        "# Post-pruning, also known as backward pruning, is a technique used to reduce the size of a decision tree after it has been fully grown (trained on the training data).  Unlike pre-pruning, which imposes restrictions during the tree's construction, post-pruning allows the tree to grow to its maximum size and then selectively removes or collapses less informative branches.\n",
        "\n",
        "# Here's how it generally works:\n",
        "\n",
        "# 1. **Full Tree Growth:** The decision tree is grown until it perfectly classifies the training data or until a very lenient stopping criterion is reached.  This often leads to a very complex tree that is likely to overfit the training data.\n",
        "\n",
        "# 2. **Evaluation Metric:** A performance metric (e.g., accuracy, F1-score, or AUC) is chosen to assess the quality of the tree.  This metric is typically evaluated on a validation set (or through cross-validation) that was not used during training.\n",
        "\n",
        "# 3. **Pruning Process:** Starting at the leaf nodes, the algorithm iteratively evaluates each node for potential pruning.  It considers removing a node and replacing it with a leaf node that has the most frequent class in the subtree rooted at that node.  The performance of the pruned tree is evaluated using the chosen metric.\n",
        "\n",
        "# 4. **Cost-Complexity Pruning:**  A common approach is Cost-Complexity Pruning, which uses a parameter (α, or the complexity parameter) that controls the trade-off between tree size and accuracy.  A larger α favors smaller trees (more pruning), while a smaller α prefers larger trees.  The algorithm finds the optimal α value that balances tree size and performance.\n",
        "\n",
        "# 5. **Validation Set:**  The pruning process is guided by the performance on the validation set.  The goal is to find the subtree that minimizes the validation error.  A pruning decision is made based on whether removing a node improves performance on the validation set.\n",
        "\n",
        "# 6. **Repeat:** Steps 3-5 are repeated until no further improvement is possible on the validation set.\n",
        "\n",
        "# **Benefits of Post-Pruning:**\n",
        "\n",
        "# * Reduced Overfitting:  Removes the unnecessary and overly specific parts of the tree, leading to better generalization.\n",
        "# * Improved Performance on Unseen Data:  A smaller, less complex tree is typically more robust to noise in the data and can generalize better.\n",
        "# * Increased Interpretability:  Pruning results in a more compact tree, which is often easier to understand and interpret.\n",
        "\n",
        "# **Example:**\n",
        "\n",
        "# Imagine a branch in a fully grown tree that only classifies a small number of instances correctly, but the parent node without this branch is only slightly less accurate. Post-pruning would evaluate this and might remove that branch, effectively simplifying the tree.\n",
        "\n",
        "# In summary, post-pruning is an important technique to improve the performance of decision trees and avoid overfitting by pruning away branches that do not generalize well.\n"
      ],
      "metadata": {
        "id": "gptwkPjTSy2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 10. What is the difference between Pre-Pruning and Post-Pruning?\n",
        "\n",
        "# Answer:\n",
        "\n",
        "# Both pre-pruning and post-pruning are techniques used to prevent overfitting in decision trees, but they differ in when and how they restrict the tree's growth:\n",
        "\n",
        "# Pre-Pruning (Early Stopping):\n",
        "\n",
        "# * **Timing:** Restrictions are applied *during* the tree's construction.\n",
        "# * **Mechanism:**  Pre-pruning sets limits on the tree's complexity *before* it's fully grown.  These limits are typically in the form of constraints like maximum depth, minimum samples per leaf, minimum impurity decrease, or maximum number of leaf nodes.\n",
        "# * **Advantages:** Computationally less expensive than post-pruning because it stops the tree growth early.  Avoids exploring unnecessary branches.\n",
        "# * **Disadvantages:**  May stop too early, potentially underfitting the data.  The optimal pruning thresholds can be difficult to determine and might not be suitable for all datasets.  It can prematurely halt the tree's exploration of promising branches.\n",
        "\n",
        "# Post-Pruning (Backward Pruning):\n",
        "\n",
        "# * **Timing:** Pruning happens *after* the tree is fully grown.\n",
        "# * **Mechanism:**  The tree is first grown to its maximum size (or a very lenient stopping criteria), and then less informative branches are selectively removed or collapsed.  This process often uses a validation set or cross-validation to evaluate the effect of pruning on generalization performance.\n",
        "# * **Advantages:** Less prone to underfitting compared to pre-pruning because the tree is initially allowed to grow fully.  It can be more effective in finding the optimal tree size for the dataset.\n",
        "# * **Disadvantages:** More computationally expensive than pre-pruning.  The full tree needs to be constructed before pruning begins.\n",
        "\n",
        "# Summary Table:\n",
        "\n",
        "# | Feature        | Pre-Pruning                               | Post-Pruning                              |\n",
        "# |----------------|-------------------------------------------|------------------------------------------|\n",
        "# | Timing         | During tree construction                  | After tree construction                   |\n",
        "# | Method         | Setting limits on tree growth             | Removing branches from a full-grown tree |\n",
        "# | Computational Cost | Lower                                    | Higher                                   |\n",
        "# | Risk           | Underfitting                               | Less likely to underfit                     |\n",
        "\n",
        "# In essence:\n",
        "\n",
        "# * Pre-pruning is like setting boundaries around the construction site of the tree.\n",
        "# * Post-pruning is like building a full-size tree and then carefully removing unnecessary branches.\n",
        "\n",
        "# The best approach often depends on the dataset, computational resources, and the desired level of interpretability.\n"
      ],
      "metadata": {
        "id": "_0EtGY5bS64h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. What is a Decision Tree Regressor? theroy\n",
        "\n",
        "# A Decision Tree Regressor is a supervised machine learning algorithm used for regression tasks.  It predicts continuous target variables by constructing a tree-like model.  Here's a breakdown:\n",
        "\n",
        "# 1. Tree Structure:  Like classification decision trees, a decision tree regressor builds a tree structure where each internal node represents a test on a feature, each branch represents an outcome of the test, and each leaf node holds a predicted value for the target variable.\n",
        "\n",
        "# 2. Prediction: To predict the target variable for a new data point, the algorithm traverses the tree from the root to a leaf node, following the decision rules at each internal node. The predicted value at the leaf node is the output.\n",
        "\n",
        "# 3. Splitting Criteria:  Unlike classification trees that use impurity measures like Gini Impurity or Entropy, regression trees use different metrics to determine the best split at each node.  Common criteria include:\n",
        "#    * **Mean Squared Error (MSE):** Measures the average squared difference between the actual target values and the predicted values in a given node.  Lower MSE indicates better predictions within a node.\n",
        "#    * **Mean Absolute Error (MAE):** Measures the average absolute difference between the actual and predicted target values.\n",
        "#    * **Variance Reduction:**  Quantifies the reduction in variance of the target variable after a split.\n",
        "\n",
        "# 4. Recursive Partitioning:  Similar to classification trees, a decision tree regressor recursively partitions the data into subsets based on splitting criteria. The goal is to create leaf nodes where the target values are as homogeneous as possible.\n",
        "\n",
        "# 5. Pruning: To avoid overfitting, pruning techniques (pre-pruning or post-pruning) are used.\n",
        "\n",
        "# 6. Handling Continuous Features: Regression trees can handle both categorical and continuous features, but special considerations are needed for continuous features. At each node, a threshold is determined to divide the data into two subsets based on the value of the feature relative to the threshold. The threshold is chosen to maximize the splitting criterion (e.g., minimizing MSE).\n",
        "\n",
        "# Example:\n",
        "# Imagine predicting the price of a house based on its size and location. A decision tree regressor might first split the data based on size (e.g., size > 1500 sq ft), then further split based on location (e.g., near a park).  Each leaf node would then contain the average price of houses within that specific category (e.g., houses > 1500 sq ft and near a park).\n",
        "\n",
        "# Advantages:\n",
        "\n",
        "# * Easy to understand and interpret.  The tree structure is intuitive and visually represents the decision-making process.\n",
        "# * Can handle both categorical and numerical features.\n",
        "# * Non-parametric: No assumptions about the underlying data distribution.\n",
        "\n",
        "# Disadvantages:\n",
        "\n",
        "# * Prone to overfitting if not properly pruned.\n",
        "# * Can be unstable: small variations in the data can lead to significantly different tree structures.\n",
        "# * Not as accurate as some other regression methods for complex datasets.\n"
      ],
      "metadata": {
        "id": "jRWFdlx6S_Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. What are the advantages and disadvantages of Decision Trees?\n",
        "\n",
        "# Advantages and Disadvantages of Decision Trees\n",
        "\n",
        "# Advantages:\n",
        "\n",
        "# 1. Easy to Understand and Interpret: Decision trees are visually appealing and easy to grasp, even for non-experts.  The tree structure provides a clear representation of the decision-making process, making it easy to explain how predictions are made.\n",
        "\n",
        "# 2. Handles both Categorical and Numerical Data: Decision trees can work with both categorical (e.g., color, gender) and numerical (e.g., age, income) features without requiring extensive data transformations.\n",
        "\n",
        "# 3. Non-Parametric: Decision trees don't assume any specific underlying distribution for the data.  This makes them robust to outliers and non-linear relationships between features and target variables.\n",
        "\n",
        "# 4. Relatively Fast Training: Compared to some other machine learning algorithms, decision trees are relatively fast to train, especially when the data set is not too large.\n",
        "\n",
        "\n",
        "# 5. Feature Importance: Decision trees provide a measure of feature importance, indicating which features are most influential in making predictions.  This can be useful for feature selection and understanding the data.\n",
        "\n",
        "\n",
        "# Disadvantages:\n",
        "\n",
        "# 1. Prone to Overfitting: Decision trees can be highly sensitive to small variations in the training data, potentially leading to overfitting.  An overfitted tree may perform very well on the training data but poorly on unseen data.  Pruning techniques help mitigate this.\n",
        "\n",
        "# 2. Instability: Small changes in the training data can result in significantly different tree structures.  This instability can be addressed with ensemble methods like random forests or gradient boosting.\n",
        "\n",
        "# 3. Bias Towards Features with Many Categories: Decision trees tend to favor features with many categories, potentially leading to biased results if not carefully addressed.\n",
        "\n",
        "# 4. Not Suitable for Very Complex Relationships: For highly complex relationships between features and target variables, decision trees might not capture these relationships as effectively as other models, such as neural networks.\n",
        "\n",
        "# 5. Sensitive to Noisy Data: Decision trees can be sensitive to noisy data, where slight errors in the training data can lead to incorrect splits.\n",
        "\n",
        "# 6. Greedy Approach: The decision tree algorithm uses a greedy approach, meaning it makes the best local decision at each node without considering the overall impact on the entire tree.  This may result in a suboptimal overall tree structure.\n"
      ],
      "metadata": {
        "id": "gr03AkG9TN7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #  : 13. How does a Decision Tree handle missing values? theory\n",
        "\n",
        "# Decision trees handle missing values in a few ways, primarily through imputation or surrogate splits:\n",
        "\n",
        "# **1. Imputation:**  This involves replacing missing values with a substitute.  Common imputation methods include:\n",
        "\n",
        "# * **Mean/Median/Mode Imputation:**  For numerical features, the missing values are replaced by the mean or median of the non-missing values for that feature. For categorical features, the mode (most frequent value) is used.  This is simple but can distort the data distribution.\n",
        "# * **Regression Imputation:** A regression model is used to predict the missing values based on the other features.  This can be more accurate but adds computational complexity.\n",
        "# * **K-Nearest Neighbors (KNN) Imputation:** The missing values are replaced by the average (for numerical) or mode (for categorical) of the values from the k-nearest neighbors in the feature space. This is generally better than mean/median imputation as it takes the values of other nearby data points into account.\n",
        "\n",
        "\n",
        "# **2. Surrogate Splits:**  Instead of directly using a feature with missing values for a split, a surrogate variable is identified.  A surrogate variable is another feature that is highly correlated with the primary feature, and it's used for splitting instances with missing values in the primary feature. The tree looks for the best surrogate feature that mimics the splits made by the original feature.\n",
        "\n",
        "# **3. Ignoring the Missing Values:** Some algorithms may simply ignore instances (rows) with missing values. This can reduce the size of the dataset and lead to bias if the missing values are not missing completely at random.\n",
        "\n",
        "# **4. Special Treatment in Algorithms:** Some algorithms will place instances with missing values in a separate branch for a given attribute.\n",
        "\n",
        "# The best method depends on the specific dataset, the prevalence of missing values, and the nature of the missing data mechanism.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2epo8SADTXDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  : 14. How does a Decision Tree handle categorical features?\n",
        "\n",
        "# 14. How does a Decision Tree handle categorical features?\n",
        "\n",
        "# Decision trees handle categorical features by creating branches for each possible category value.  Here's a breakdown:\n",
        "\n",
        "# 1. **Splitting Criteria:** At each node, the algorithm evaluates different categorical features and their possible values to determine the best split.  Unlike continuous features where a threshold is used, categorical features are split based on the categories themselves.\n",
        "\n",
        "# 2. **Decision Rules:** For a given categorical feature, the decision rule at a node checks if the value of that feature for a particular instance matches one of the categories.  Based on the match, the instance is directed down the corresponding branch.\n",
        "\n",
        "# 3. **Impurity Measures:** The effectiveness of a split is measured using impurity measures (like Gini impurity or entropy). The algorithm aims to find the split that maximizes the reduction in impurity.\n",
        "\n",
        "# 4. **Handling Multiple Categories:**  A feature with multiple categories will lead to multiple branches from a single node, one branch for each category.\n",
        "\n",
        "# 5. **Example:**  Suppose you have a feature \"color\" with categories \"red\", \"green\", and \"blue\".  At a node, the tree might split into three branches, one for each color.  Instances with \"red\" color will go down the \"red\" branch, and so on.\n",
        "\n",
        "\n",
        "# **Handling Binary vs. Multi-category features**\n",
        "\n",
        "# *Binary Features*: These can be treated as any other categorical feature by simply having two branches stemming from a node.\n",
        "# *Multi-category Features*:  The split at a node for a multi-categorical feature effectively partitions the data into subsets, one for each category value.\n",
        "\n",
        "\n",
        "# **Encoding**:\n",
        "\n",
        "# It's worth noting that some decision tree implementations may work with numerical representations of categorical variables (e.g., one-hot encoding, label encoding), but the core principle remains the same: the algorithm partitions the data based on the distinct categories of the feature.\n"
      ],
      "metadata": {
        "id": "NqYNKdpjTe2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 15. What are some real-world applications of Decision Trees?\n",
        "\n",
        "# Decision trees have a wide range of applications in various fields due to their interpretability and ability to handle both categorical and numerical data. Here are some examples:\n",
        "\n",
        "# 1. Customer Relationship Management (CRM):\n",
        "#    * **Churn prediction:**  Identify customers at risk of leaving a service or product.\n",
        "#    * **Customer segmentation:** Group customers based on their characteristics and behavior to tailor marketing campaigns.\n",
        "#    * **Recommendation systems:** Suggest products or services that are likely to be of interest to a customer.\n",
        "\n",
        "# 2. Healthcare:\n",
        "#    * **Disease diagnosis:** Assist in diagnosing diseases based on symptoms and medical history.\n",
        "#    * **Patient risk assessment:**  Predict the likelihood of patients developing certain conditions.\n",
        "#    * **Treatment selection:**  Help doctors decide on the most appropriate treatment options.\n",
        "\n",
        "\n",
        "# 3. Finance:\n",
        "#    * **Credit risk assessment:** Evaluate the creditworthiness of loan applicants.\n",
        "#    * **Fraud detection:** Identify fraudulent transactions.\n",
        "#    * **Investment decisions:** Assist investors in making informed decisions.\n",
        "\n",
        "# 4. Marketing:\n",
        "#    * **Target marketing:** Identify the most promising customer segments for specific products or services.\n",
        "#    * **Campaign optimization:**  Improve the effectiveness of marketing campaigns.\n",
        "\n",
        "# 5. Retail:\n",
        "#    * **Inventory management:** Predict future demand for products.\n",
        "#    * **Sales forecasting:**  Estimate future sales based on historical data.\n",
        "#    * **Price optimization:** Determine the optimal price for products.\n",
        "\n",
        "# 6. Manufacturing:\n",
        "#    * **Quality control:** Identify defects in manufacturing processes.\n",
        "#    * **Predictive maintenance:**  Predict when equipment is likely to fail.\n",
        "\n",
        "# 7. Education:\n",
        "#    * **Student performance prediction:** Estimate student performance based on various factors.\n",
        "#    * **Dropout prediction:** Identify students at risk of dropping out of school.\n",
        "\n",
        "# 8. Image Processing:\n",
        "#    * **Object recognition:** In some image recognition tasks where interpretability is valued over extremely high accuracy.\n",
        "\n",
        "# 9. Other areas:\n",
        "#    * **Bioinformatics:** Analyze biological data and build predictive models\n",
        "#    * **Environmental science:** Analyze environmental patterns.\n",
        "\n",
        "\n",
        "\n",
        "# These are just a few examples; the applications of decision trees are constantly expanding as new techniques and technologies emerge.\n"
      ],
      "metadata": {
        "id": "EZ7xvXI1TllD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n29eV4zATrHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Practical**"
      ],
      "metadata": {
        "id": "wyGROgF1Wb2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Write a Python program to train a Decision Tree Classifier on the Iris dataset and print the model accuracy.\n",
        "Approach: Use DecisionTreeClassifier from sklearn.tree to train on the Iris dataset and evaluate accuracy on a test set.**"
      ],
      "metadata": {
        "id": "KjItxZ4NUl-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sY6VLW0Up7H",
        "outputId": "39a54716-b210-4e30-c4b7-a4b32ec14a04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Write a Python program to train a Decision Tree Classifier using Gini Impurity as the criterion and print the feature importances.\n",
        "Approach: Use DecisionTreeClassifier with criterion='gini' and access feature importance scores via feature_importances_.**"
      ],
      "metadata": {
        "id": "kbA21lWvUvzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier with Gini criterion\n",
        "dt = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importances\n",
        "feature_names = data.feature_names\n",
        "importances = dt.feature_importances_\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"Feature: {name}, Importance: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvaOfU3zU2Uu",
        "outputId": "f2a59d86-5dc1-4c3c-eff7-646ba8d0fec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: sepal length (cm), Importance: 0.0000\n",
            "Feature: sepal width (cm), Importance: 0.0167\n",
            "Feature: petal length (cm), Importance: 0.9061\n",
            "Feature: petal width (cm), Importance: 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. Write a Python program to train a Decision Tree Classifier using Entropy as the splitting criterion and print the model accuracy.\n",
        "Approach: Use DecisionTreeClassifier with criterion='entropy' and evaluate accuracy."
      ],
      "metadata": {
        "id": "qwlGsYt3U8LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier with Entropy criterion\n",
        "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VrhBnN3U_il",
        "outputId": "5244affe-85f1-4b85-807e-992f5608a322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHX8E3ENU_yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "19. Write a Python program to train a Decision Tree Regressor on a housing dataset and evaluate using Mean Squared Error (MSE).\n",
        "Approach: Use DecisionTreeRegressor on the California housing dataset (or a synthetic dataset if the housing dataset is unavailable) and evaluate using MSE."
      ],
      "metadata": {
        "id": "AOhYf-xRVCAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor\n",
        "dt = DecisionTreeRegressor(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = dt.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMpaVFfmVCjB",
        "outputId": "1acbac2a-0e31-4859-80ca-e19c0d7e8617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5xlhpsAAVDwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "20. Write a Python program to train a Decision Tree Classifier and visualize the tree using graphviz.\n",
        "Approach: Use DecisionTreeClassifier, export the tree structure using export_graphviz, and visualize it using graphviz."
      ],
      "metadata": {
        "id": "4MXMbVCCVGKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import graphviz\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(max_depth=3, random_state=42)  # Limit depth for visualization\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Export tree to DOT format\n",
        "dot_data = export_graphviz(dt, out_file=None,\n",
        "                           feature_names=data.feature_names,\n",
        "                           class_names=data.target_names,\n",
        "                           filled=True, rounded=True,\n",
        "                           special_characters=True)\n",
        "\n",
        "# Visualize the tree\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"iris_decision_tree\", view=True)  # Saves and opens the visualization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RfLplOCAVGZ9",
        "outputId": "d7d859b6-69ed-43af-aa34-541f4b9ca642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'iris_decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4nV13UvPVKSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. Write a Python program to train a Decision Tree Classifier with a maximum depth of 3 and compare its accuracy with a fully grown tree.\n",
        "Approach: Train two DecisionTreeClassifier models—one with max_depth=3 and one unrestricted—and compare accuracy."
      ],
      "metadata": {
        "id": "S-LkfhUaVOUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree with max_depth=3\n",
        "dt_limited = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_limited.fit(X_train, y_train)\n",
        "y_pred_limited = dt_limited.predict(X_test)\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "# Train fully grown Decision Tree\n",
        "dt_full = DecisionTreeClassifier(random_state=42)\n",
        "dt_full.fit(X_train, y_train)\n",
        "y_pred_full = dt_full.predict(X_test)\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "\n",
        "# Compare accuracy\n",
        "print(f\"Accuracy with max_depth=3: {accuracy_limited:.2f}\")\n",
        "print(f\"Accuracy with fully grown tree: {accuracy_full:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SyLwP5aVOul",
        "outputId": "da587c44-2bff-4976-9562-b6f2a1428f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=3: 1.00\n",
            "Accuracy with fully grown tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uVX2fxGgVQIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. Write a Python program to train a Decision Tree Classifier using min_samples_split=5 and compare its accuracy with a default tree.\n",
        "Approach: Train two DecisionTreeClassifier models—one with min_samples_split=5 and one with default settings—and compare accuracy."
      ],
      "metadata": {
        "id": "CKwPbLnfVSeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree with min_samples_split=5\n",
        "dt_split = DecisionTreeClassifier(min_samples_split=5, random_state=42)\n",
        "dt_split.fit(X_train, y_train)\n",
        "y_pred_split = dt_split.predict(X_test)\n",
        "accuracy_split = accuracy_score(y_test, y_pred_split)\n",
        "\n",
        "# Train default Decision Tree\n",
        "dt_default = DecisionTreeClassifier(random_state=42)\n",
        "dt_default.fit(X_train, y_train)\n",
        "y_pred_default = dt_default.predict(X_test)\n",
        "accuracy_default = accuracy_score(y_test, y_pred_default)\n",
        "\n",
        "# Compare accuracy\n",
        "print(f\"Accuracy with min_samples_split=5: {accuracy_split:.2f}\")\n",
        "print(f\"Accuracy with default tree: {accuracy_default:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiajTBg-VSyc",
        "outputId": "9568c503-12d3-4ba5-eeac-e421d509bfce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with min_samples_split=5: 1.00\n",
            "Accuracy with default tree: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uHH5IU7pVUgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. Write a Python program to apply feature scaling before training a Decision Tree Classifier and compare its accuracy with unscaled data.\n",
        "Approach: Train two DecisionTreeClassifier models—one on scaled data using StandardScaler and one on unscaled data—and compare accuracy. Note that Decision Trees are invariant to feature scaling, so the accuracy should be the same."
      ],
      "metadata": {
        "id": "9IWAwU-cVXH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Decision Tree on scaled data\n",
        "dt_scaled = DecisionTreeClassifier(random_state=42)\n",
        "dt_scaled.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = dt_scaled.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Train Decision Tree on unscaled data\n",
        "dt_unscaled = DecisionTreeClassifier(random_state=42)\n",
        "dt_unscaled.fit(X_train, y_train)\n",
        "y_pred_unscaled = dt_unscaled.predict(X_test)\n",
        "accuracy_unscaled = accuracy_score(y_test, y_pred_unscaled)\n",
        "\n",
        "# Compare accuracy\n",
        "print(f\"Accuracy with scaled data: {accuracy_scaled:.2f}\")\n",
        "print(f\"Accuracy with unscaled data: {accuracy_unscaled:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbZCusslVXd9",
        "outputId": "5ffb3045-b42b-45fb-a6b4-1b16ee62577e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with scaled data: 1.00\n",
            "Accuracy with unscaled data: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N_KyAexLVZca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "24. Write a Python program to train a Decision Tree Classifier using One-vs-Rest (OvR) strategy for multiclass classification.\n",
        "Approach: Decision Trees in scikit-learn handle multiclass classification natively without needing an explicit OvR strategy. However, to demonstrate OvR, we can use OneVsRestClassifier with a Decision Tree as the base estimator.\n"
      ],
      "metadata": {
        "id": "9VYgNZR9VeIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree with One-vs-Rest strategy\n",
        "ovr_classifier = OneVsRestClassifier(DecisionTreeClassifier(random_state=42))\n",
        "ovr_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = ovr_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy with OvR: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juBi0RUmVe12",
        "outputId": "fa2afe62-78a5-4d46-a13d-72839d4064d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy with OvR: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMtl5000VgyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "25. Write a Python program to train a Decision Tree Classifier and display the feature importance scores.\n",
        "Approach: Use DecisionTreeClassifier and access feature importance scores via feature_importances_."
      ],
      "metadata": {
        "id": "jxvnvKMTVrAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Display feature importance scores\n",
        "feature_names = data.feature_names\n",
        "importances = dt.feature_importances_\n",
        "for name, importance in zip(feature_names, importances):\n",
        "    print(f\"Feature: {name}, Importance: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fM-8B0zYVrjE",
        "outputId": "7dba606a-abbd-46da-aace-ac16367c0c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature: sepal length (cm), Importance: 0.0000\n",
            "Feature: sepal width (cm), Importance: 0.0167\n",
            "Feature: petal length (cm), Importance: 0.9061\n",
            "Feature: petal width (cm), Importance: 0.0772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hQTjL-1pVuHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "26. Write a Python program to train a Decision Tree Regressor with max_depth=5 and compare its performance with an unrestricted tree.\n",
        "Approach: Train two DecisionTreeRegressor models—one with max_depth=5 and one unrestricted—and compare MSE."
      ],
      "metadata": {
        "id": "8t3TcJbaVwPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Regressor with max_depth=5\n",
        "dt_limited = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
        "dt_limited.fit(X_train, y_train)\n",
        "y_pred_limited = dt_limited.predict(X_test)\n",
        "mse_limited = mean_squared_error(y_test, y_pred_limited)\n",
        "\n",
        "# Train unrestricted Decision Tree Regressor\n",
        "dt_full = DecisionTreeRegressor(random_state=42)\n",
        "dt_full.fit(X_train, y_train)\n",
        "y_pred_full = dt_full.predict(X_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# Compare performance\n",
        "print(f\"MSE with max_depth=5: {mse_limited:.2f}\")\n",
        "print(f\"MSE with unrestricted tree: {mse_full:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lvnv6WYoVwq3",
        "outputId": "a301b271-4703-4418-d249-d6d36a7c72e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with max_depth=5: 0.52\n",
            "MSE with unrestricted tree: 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IzGLbOLRV01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "27. Write a Python program to train a Decision Tree Classifier, apply Cost Complexity Pruning (CCP), and visualize its effect on accuracy.\n",
        "Approach: Use DecisionTreeClassifier with ccp_alpha to apply Cost Complexity Pruning, and plot accuracy for different ccp_alpha values."
      ],
      "metadata": {
        "id": "aiYsstX9V3J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree and get path for CCP\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "path = dt.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
        "\n",
        "# Train Decision Trees with different ccp_alpha values and store accuracies\n",
        "accuracies = []\n",
        "for ccp_alpha in ccp_alphas:\n",
        "    dt_pruned = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n",
        "    dt_pruned.fit(X_train, y_train)\n",
        "    y_pred = dt_pruned.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Visualize the effect of ccp_alpha on accuracy\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(ccp_alphas, accuracies, marker='o')\n",
        "plt.xlabel('ccp_alpha')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Effect of Cost Complexity Pruning on Accuracy')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Print the best ccp_alpha and corresponding accuracy\n",
        "best_idx = accuracies.index(max(accuracies))\n",
        "print(f\"Best ccp_alpha: {ccp_alphas[best_idx]:.4f}\")\n",
        "print(f\"Best Accuracy: {accuracies[best_idx]:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "vz0zUOG7V3di",
        "outputId": "1266b060-90bc-4310-b69e-14a8dbc0741c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ccp_alpha: 0.0000\n",
            "Best Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oQbejc-QV5dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "28. Write a Python program to train a Decision Tree Classifier and evaluate its performance using Precision, Recall, and F1-Score.\n",
        "Approach: Use DecisionTreeClassifier and evaluate using classification_report."
      ],
      "metadata": {
        "id": "epOKijtkV8RV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = dt.predict(X_test)\n",
        "print(classification_report(y_test, y_pred, target_names=data.target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXBDLoI2V8iK",
        "outputId": "833d0981-9128-4cdd-d0e1-c55453d5dd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      1.00      1.00         9\n",
            "   virginica       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "phbh7XxHV-9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "29. Write a Python program to train a Decision Tree Classifier and visualize the confusion matrix using seaborn.\n",
        "Approach: Train DecisionTreeClassifier and use confusion_matrix and seaborn for visualization."
      ],
      "metadata": {
        "id": "0sb_jP9eWCJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute confusion matrix\n",
        "y_pred = dt.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "E4fbllk3WCZ9",
        "outputId": "84558d3a-5d91-4e38-898b-ec93b56a6f7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAAIjCAYAAACTRapjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAATVlJREFUeJzt3XmcjfX///HnGcyZMbvBmLGMtbEbomKyZUsR+RSiQqFPSMhaDWOd+BRKsmaNVkulki1ZQzK2ZB1LIbJmm2Hm+v3h6/w6ZjDDnLlO53rc3a7bzbyv67zfr3O6buPV6/2+3sdmGIYhAAAAWIaX2QEAAAAge5EAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZAAAgAAWAwJIAAAgMWQAAK4rb1796phw4YKCgqSzWbTwoULs7T/gwcPymazacaMGVna779ZnTp1VKdOHbPDAODBSACBf4H9+/frpZdeUvHixeXj46PAwEDFxMTo3Xff1eXLl106drt27bR9+3YNHz5cs2fPVtWqVV06XnZq3769bDabAgMD0/0c9+7dK5vNJpvNprfffjvT/R89elRxcXFKSEjIgmgBIOvkNDsAALf3zTff6Omnn5bdbtfzzz+v8uXLKzk5WWvWrFGfPn20c+dOTZ482SVjX758WevXr9cbb7yhbt26uWSMyMhIXb58Wbly5XJJ/3eSM2dOXbp0SV9//bVatmzpdG7OnDny8fHRlStX7qrvo0ePavDgwSpatKiio6Mz/LolS5bc1XgAkFEkgIAbS0xMVOvWrRUZGakVK1YoPDzcca5r167at2+fvvnmG5eNf/LkSUlScHCwy8aw2Wzy8fFxWf93YrfbFRMTo48//jhNAjh37lw9/vjjmjdvXrbEcunSJeXOnVve3t7ZMh4A62IKGHBjo0aN0oULF/Thhx86JX83lCxZUq+++qrj52vXrmno0KEqUaKE7Ha7ihYtqtdff11JSUlOrytatKiaNGmiNWvW6IEHHpCPj4+KFy+uWbNmOa6Ji4tTZGSkJKlPnz6y2WwqWrSopOtTpzf+/k9xcXGy2WxObUuXLtXDDz+s4OBg+fv7KyoqSq+//rrj/K3WAK5YsUI1a9aUn5+fgoOD1axZM+3atSvd8fbt26f27dsrODhYQUFB6tChgy5dunTrD/Ymbdq00XfffaezZ8862jZt2qS9e/eqTZs2aa4/ffq0evfurQoVKsjf31+BgYFq3Lixtm7d6rhm5cqVqlatmiSpQ4cOjqnkG++zTp06Kl++vDZv3qxatWopd+7cjs/l5jWA7dq1k4+PT5r336hRI4WEhOjo0aMZfq8AIJEAAm7t66+/VvHixVWjRo0MXd+xY0cNHDhQVapU0ZgxY1S7dm3Fx8erdevWaa7dt2+fnnrqKTVo0EDvvPOOQkJC1L59e+3cuVOS1KJFC40ZM0aS9Mwzz2j27NkaO3ZspuLfuXOnmjRpoqSkJA0ZMkTvvPOOnnjiCa1du/a2r1u2bJkaNWqkEydOKC4uTr169dK6desUExOjgwcPprm+ZcuW+vvvvxUfH6+WLVtqxowZGjx4cIbjbNGihWw2m+bPn+9omzt3rkqXLq0qVaqkuf7AgQNauHChmjRpotGjR6tPnz7avn27ateu7UjGypQpoyFDhkiSOnfurNmzZ2v27NmqVauWo59Tp06pcePGio6O1tixY1W3bt1043v33XeVL18+tWvXTikpKZKkSZMmacmSJRo3bpwiIiIy/F4BQJJkAHBL586dMyQZzZo1y9D1CQkJhiSjY8eOTu29e/c2JBkrVqxwtEVGRhqSjFWrVjnaTpw4YdjtduO1115ztCUmJhqSjP/9739OfbZr186IjIxME8OgQYOMf/5aGTNmjCHJOHny5C3jvjHG9OnTHW3R0dFG/vz5jVOnTjnatm7danh5eRnPP/98mvFeeOEFpz6ffPJJIzQ09JZj/vN9+Pn5GYZhGE899ZRRr149wzAMIyUlxShQoIAxePDgdD+DK1euGCkpKWneh91uN4YMGeJo27RpU5r3dkPt2rUNScbEiRPTPVe7dm2ntu+//96QZAwbNsw4cOCA4e/vbzRv3vyO7xEA0kMFEHBT58+flyQFBARk6Ppvv/1WktSrVy+n9tdee02S0qwVLFu2rGrWrOn4OV++fIqKitKBAwfuOuab3Vg7+OWXXyo1NTVDrzl27JgSEhLUvn175cmTx9FesWJFNWjQwPE+/+m///2v0881a9bUqVOnHJ9hRrRp00YrV67U8ePHtWLFCh0/fjzd6V/p+rpBL6/rvz5TUlJ06tQpx/T2L7/8kuEx7Xa7OnTokKFrGzZsqJdeeklDhgxRixYt5OPjo0mTJmV4LAD4JxJAwE0FBgZKkv7+++8MXX/o0CF5eXmpZMmSTu0FChRQcHCwDh065NRepEiRNH2EhITozJkzdxlxWq1atVJMTIw6duyosLAwtW7dWp999tltk8EbcUZFRaU5V6ZMGf3111+6ePGiU/vN7yUkJESSMvVeHnvsMQUEBOjTTz/VnDlzVK1atTSf5Q2pqakaM2aMSpUqJbvdrrx58ypfvnzatm2bzp07l+ExCxYsmKkHPt5++23lyZNHCQkJeu+995Q/f/4MvxYA/okEEHBTgYGBioiI0I4dOzL1upsfwriVHDlypNtuGMZdj3FjfdoNvr6+WrVqlZYtW6bnnntO27ZtU6tWrdSgQYM0196Le3kvN9jtdrVo0UIzZ87UggULbln9k6QRI0aoV69eqlWrlj766CN9//33Wrp0qcqVK5fhSqd0/fPJjC1btujEiROSpO3bt2fqtQDwTySAgBtr0qSJ9u/fr/Xr19/x2sjISKWmpmrv3r1O7X/++afOnj3reKI3K4SEhDg9MXvDzVVGSfLy8lK9evU0evRo/frrrxo+fLhWrFihH374Id2+b8S5e/fuNOd+++035c2bV35+fvf2Bm6hTZs22rJli/7+++90H5y54YsvvlDdunX14YcfqnXr1mrYsKHq16+f5jPJaDKeERcvXlSHDh1UtmxZde7cWaNGjdKmTZuyrH8A1kICCLixvn37ys/PTx07dtSff/6Z5vz+/fv17rvvSro+hSkpzZO6o0ePliQ9/vjjWRZXiRIldO7cOW3bts3RduzYMS1YsMDputOnT6d57Y0NkW/emuaG8PBwRUdHa+bMmU4J1Y4dO7RkyRLH+3SFunXraujQoXr//fdVoECBW16XI0eONNXFzz//XH/88YdT241ENb1kObP69eunw4cPa+bMmRo9erSKFi2qdu3a3fJzBIDbYSNowI2VKFFCc+fOVatWrVSmTBmnbwJZt26dPv/8c7Vv316SVKlSJbVr106TJ0/W2bNnVbt2bW3cuFEzZ85U8+bNb7nFyN1o3bq1+vXrpyeffFLdu3fXpUuXNGHCBN13331OD0EMGTJEq1at0uOPP67IyEidOHFCH3zwgQoVKqSHH374lv3/73//U+PGjVW9enW9+OKLunz5ssaNG6egoCDFxcVl2fu4mZeXl9588807XtekSRMNGTJEHTp0UI0aNbR9+3bNmTNHxYsXd7quRIkSCg4O1sSJExUQECA/Pz89+OCDKlasWKbiWrFihT744AMNGjTIsS3N9OnTVadOHcXGxmrUqFGZ6g8A2AYG+BfYs2eP0alTJ6No0aKGt7e3ERAQYMTExBjjxo0zrly54rju6tWrxuDBg41ixYoZuXLlMgoXLmwMGDDA6RrDuL4NzOOPP55mnJu3H7nVNjCGYRhLliwxypcvb3h7extRUVHGRx99lGYbmOXLlxvNmjUzIiIiDG9vbyMiIsJ45plnjD179qQZ4+atUpYtW2bExMQYvr6+RmBgoNG0aVPj119/dbrmxng3bzMzffp0Q5KRmJh4y8/UMJy3gbmVW20D89prrxnh4eGGr6+vERMTY6xfvz7d7Vu+/PJLo2zZskbOnDmd3mft2rWNcuXKpTvmP/s5f/68ERkZaVSpUsW4evWq03U9e/Y0vLy8jPXr19/2PQDAzWyGkYlV0gAAAPjXYw0gAACAxZAAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxXjkN4H4Nh5jdghAGme+7ml2CADg1nxMzEp8K3dzWd+Xt7zvsr7vFhVAAAAAi/HICiAAAECm2KxVEyMBBAAAsNnMjiBbWSvdBQAAABVAAAAAq00BW+vdAgAAgAogAAAAawABAADg0agAAgAAsAYQAAAAnowKIAAAgMXWAJIAAgAAMAUMAAAAT0YFEAAAwGJTwFQAAQAALIYKIAAAAGsAAQAA4MmoAAIAALAGEAAAAJ6MCiAAAIDF1gCSAAIAADAFDAAAAE9GBRAAAMBiU8DWercAAACgAggAAEAFEAAAAB6NCiAAAIAXTwEDAADAg1EBBAAAsNgaQBJAAAAANoIGAACAJ6MCCAAAYLEpYGu9WwAAAFABBAAAYA0gAAAAPBoVQAAAANYAAgAAwJORAAIAANhsrjsyadWqVWratKkiIiJks9m0cOFCp/OGYWjgwIEKDw+Xr6+v6tevr71792ZqDBJAAAAAm5frjky6ePGiKlWqpPHjx6d7ftSoUXrvvfc0ceJEbdiwQX5+fmrUqJGuXLmS4TFYAwgAAOBGGjdurMaNG6d7zjAMjR07Vm+++aaaNWsmSZo1a5bCwsK0cOFCtW7dOkNjUAEEAABw4RRwUlKSzp8/73QkJSXdVZiJiYk6fvy46tev72gLCgrSgw8+qPXr12e4HxJAAAAAF4qPj1dQUJDTER8ff1d9HT9+XJIUFhbm1B4WFuY4lxFMAQMAALhwG5gBAwaoV69eTm12u91l42UECSAAAIAL2e32LEv4ChQoIEn6888/FR4e7mj/888/FR0dneF+mAIGAABwo21gbqdYsWIqUKCAli9f7mg7f/68NmzYoOrVq2e4HyqAAAAAbuTChQvat2+f4+fExEQlJCQoT548KlKkiHr06KFhw4apVKlSKlasmGJjYxUREaHmzZtneAwSQAAAADf6Kriff/5ZdevWdfx8Y/1gu3btNGPGDPXt21cXL15U586ddfbsWT388MNavHixfHx8MjyGzTAMI8sjN5lv4zFmhwCkcebrnmaHAABuzcfEspRv0w9c1vflr7u4rO+75T7pLgAAALIFU8AAAABZ/LCGu6MCCAAAYDFUAAEAANzoIZDsYK13CwAAACqAAAAArAEEAACAR6MCCAAAYLE1gG6VAF65ckXJyclObYGBgSZFAwAALIMp4Ox16dIldevWTfnz55efn59CQkKcDgAAAGQt0xPAPn36aMWKFZowYYLsdrumTp2qwYMHKyIiQrNmzTI7PAAAYAE2m81lhzsyfQr466+/1qxZs1SnTh116NBBNWvWVMmSJRUZGak5c+aobdu2ZocIAADgUUyvAJ4+fVrFixeXdH293+nTpyVJDz/8sFatWmVmaAAAwCKsVgE0PQEsXry4EhMTJUmlS5fWZ599Jul6ZTA4ONjEyAAAADyT6Qlghw4dtHXrVklS//79NX78ePn4+Khnz57q06ePydEBAABLsLnwcEOmrwHs2bOn4+/169fXb7/9ps2bN6tkyZKqWLGiiZEBAAB4JtMTwJtFRkYqKCiI6V8AAJBt3HWtnquYPgU8cuRIffrpp46fW7ZsqdDQUBUsWNAxNQwAAOBKPASSzSZOnKjChQtLkpYuXaqlS5fqu+++U+PGjVkDCAAA4AKmTwEfP37ckQAuWrRILVu2VMOGDVW0aFE9+OCDJkcHAACswF0rda5iegUwJCRER44ckSQtXrxY9evXlyQZhqGUlBQzQwMAAPBIplcAW7RooTZt2qhUqVI6deqUGjduLEnasmWLSpYsaXJ0AADACqgAZrMxY8aoW7duKlu2rJYuXSp/f39J0rFjx9SlSxeTo7OGmPIF9UVcMx34qJMuf9dTTauXSHNN7HPVdWBOZ51e+Iq+GfEflYgIzv5AYXmfzJ2jxg0eUbXKFdS29dPavm2b2SHB4rgn8W9legKYK1cu9e7dW++++64qV67saO/Zs6c6duxoYmTW4eeTS9sPnFSPD1ake/61p6uqyxPR6j5umWr1+FgXr1zV18NayJ4rRzZHCitb/N23entUvF7q0lWffL5AUVGl9fJLL+rUqVNmhwaL4p70MBbbCNr0BFCS9u/fr1deeUX169dX/fr11b17dx04cMDssCxjyc8HNXjWOn21bn+657s2r6KRn2zUop8OaMfBv9Tx7cUKD/XTEzXSVgoBV5k9c7paPNVSzZ/8j0qULKk3Bw2Wj4+PFs6fZ3ZosCjuSfybmZ4Afv/99ypbtqw2btyoihUrqmLFitqwYYNjShjmKlogSOF5/LRiy2FH2/lLydq0+7geLB1hYmSwkqvJydr16049VL2Go83Ly0sPPVRD27ZuMTEyWBX3pOex2j6Apj8E0r9/f/Xs2VNvvfVWmvZ+/fqpQYMGJkUGSSoQkluSdOLMJaf2E2cuKez/zgGudubsGaWkpCg0NNSpPTQ0VImJzBYg+3FP4t/O9ARw165d+uyzz9K0v/DCCxo7duwdX5+UlKSkpCSnNiP1mmxepr81AADwL+GulTpXMX0KOF++fEpISEjTnpCQoPz589/x9fHx8QoKCnI6ru1f5oJIren4/1X+8t9U7csfklt/3lQVBFwlJDhEOXLkSLO4/tSpU8qbN69JUcHKuCc9j9WmgE1PADt16qTOnTtr5MiRWr16tVavXq233npLL730kjp16nTH1w8YMEDnzp1zOnKWqJ8NkVvDwePndOz0RdWNLuxoC8jtrWpRBbTht6MmRgYryeXtrTJly2nDT+sdbampqdqwYb0qVqp8m1cCrsE9iX870+dJY2NjFRAQoHfeeUcDBgyQJEVERCguLk7du3e/4+vtdrvsdrtTG9O/mePnk8tpX7+iYYGqWDyfzvx9RUdO/q3xC39Rv9YPat8fZ3Xwz3Ma9FwNHTt18ZZPDQOu8Fy7Dop9vZ/KlSuv8hUq6qPZM3X58mU1f7KF2aHBorgnPYu7VupcxfRMyWazqWfPnurZs6f+/vtvSVJAQIDJUVlLlVJhWjLqacfPo16qI0mavXSnOo9eonc+/1m5fXLp/e71Fexv17qdR/VE7HwlXeWr+pB9Hm38mM6cPq0P3n9Pf/11UlGly+iDSVMVynQbTMI9iX8zm2EYhpkBPPLII5o/f76Cg4Od2s+fP6/mzZtrxYr0Nye+Hd/GY7IoOiDrnPm6p9khAIBb8zGxLBXa7mOX9X1q5jMu6/tumb4GcOXKlUpOTk7TfuXKFa1evdqEiAAAADybabn2tn98X+Kvv/6q48ePO35OSUnR4sWLVbBgQTNCAwAAFsMawGwSHR3teDz6kUceSXPe19dX48aNMyEyAAAAz2ZaApiYmCjDMFS8eHFt3LhR+fLlc5zz9vZW/vz5lSNHDrPCAwAAFkIFMJtERkZKur5vEgAAgJmslgCa/hCIJM2ePVsxMTGKiIjQoUOHJEljxozRl19+aXJkAAAAnsf0BHDChAnq1auXHnvsMZ09e1YpKdf3lgsJCcnQdwEDAADcM5sLDzdkegI4btw4TZkyRW+88YbTmr+qVatq+/btJkYGAADgmUz/JpDExERVrpz2exPtdrsuXrxoQkQAAMBqWAOYzYoVK6aEhIQ07YsXL1aZMmWyPyAAAAAPZ3oFsFevXuratauuXLkiwzC0ceNGffzxx4qPj9fUqVPNDg8AAFiA1SqApieAHTt2lK+vr958801dunRJbdq0UcGCBfXuu++qdevWZocHAADgcUxPAC9fvqwnn3xSbdu21aVLl7Rjxw6tXbtWhQoVMjs0AABgEVarAJq+BrBZs2aaNWuWJCk5OVlPPPGERo8erebNm2vChAkmRwcAAKzgxtfTuuJwR6YngL/88otq1qwpSfriiy8UFhamQ4cOadasWXrvvfdMjg4AAMDzmD4FfOnSJQUEBEiSlixZohYtWsjLy0sPPfSQ41tBAAAAXMo9C3UuY3oFsGTJklq4cKGOHDmi77//Xg0bNpQknThxQoGBgSZHBwAA4HlMTwAHDhyo3r17q2jRonrwwQdVvXp1SdergeltEA0AAJDVrLYG0PQp4KeeekoPP/ywjh07pkqVKjna69WrpyeffNLEyAAAADyT6QmgJBUoUEAFChRwanvggQdMigYAAFiNu1bqXMX0KWAAAABkL7eoAAIAAJjJahVAEkAAAABr5X9MAQMAAFgNFUAAAGB5VpsCpgIIAABgMVQAAQCA5VEBBAAAgEejAggAACyPCiAAAAA8GhVAAABgeVarAJIAAgAAWCv/YwoYAADAaqgAAgAAy7PaFDAVQAAAAIuhAggAACyPCiAAAAA8GhVAAABgeRYrAFIBBAAAsBoqgAAAwPJYAwgAAGAxNpvrjsxISUlRbGysihUrJl9fX5UoUUJDhw6VYRhZ+n6pAAIAALiJkSNHasKECZo5c6bKlSunn3/+WR06dFBQUJC6d++eZeOQAAIAAMtzlyngdevWqVmzZnr88cclSUWLFtXHH3+sjRs3Zuk4TAEDAAC4UFJSks6fP+90JCUlpXttjRo1tHz5cu3Zs0eStHXrVq1Zs0aNGzfO0phIAAEAgOW5cg1gfHy8goKCnI74+Ph04+jfv79at26t0qVLK1euXKpcubJ69Oihtm3bZun7ZQoYAADAhQYMGKBevXo5tdnt9nSv/eyzzzRnzhzNnTtX5cqVU0JCgnr06KGIiAi1a9cuy2IiAQQAAJbn5eW6NYB2u/2WCd/N+vTp46gCSlKFChV06NAhxcfHZ2kCyBQwAACAm7h06ZK8vJzTsxw5cig1NTVLx6ECCAAALM9NHgJW06ZNNXz4cBUpUkTlypXTli1bNHr0aL3wwgtZOg4JIAAAsDx32QZm3Lhxio2NVZcuXXTixAlFRETopZde0sCBA7N0HBJAAAAANxEQEKCxY8dq7NixLh2HBBAAAFiemxQAsw0PgQAAAFgMFUAAAGB57rIGMLtQAQQAALAYKoAAAMDyqAACAADAo1EBBAAAlmexAiAJIAAAAFPAAAAA8GhUAAEAgOVZrABIBRAAAMBqqAACAADLYw0gAAAAPBoVQAAAYHkWKwBSAQQAALAaKoAAAMDyWAMIAAAAj0YFEAAAWJ7FCoAkgAAAAEwBAwAAwKNRAQQAAJZnsQKgZyaAZ77uaXYIQBqFOn5idgiAk9+ntjY7BAAm8cgEEAAAIDNYAwgAAACPRgUQAABYnsUKgFQAAQAArIYKIAAAsDyrrQEkAQQAAJZnsfyPKWAAAACroQIIAAAsz2pTwFQAAQAALIYKIAAAsDwqgAAAAPBoVAABAIDlWawASAUQAADAaqgAAgAAy7PaGkASQAAAYHkWy/+YAgYAALAaKoAAAMDyrDYFTAUQAADAYqgAAgAAy7NYAZAKIAAAgNVQAQQAAJbnZbESIBVAAAAAi6ECCAAALM9iBUASQAAAALaBAQAAgEejAggAACzPy1oFQCqAAAAAVkMFEAAAWB5rAAEAAODRqAACAADLs1gBkAogAACA1VABBAAAlmeTtUqAJIAAAMDy2AYGAAAAHo0KIAAAsDy2gQEAAIBHowIIAAAsz2IFQCqAAAAAVkMFEAAAWJ6XxUqAVAABAAAshgogAACwPIsVAEkAAQAA2AYGAAAAHo0KIAAAsDyLFQDNrQBevXpV9erV0969e80MAwAAwFJMrQDmypVL27ZtMzMEAAAAtoHJbs8++6w+/PBDs8MAAACwDNPXAF67dk3Tpk3TsmXLdP/998vPz8/p/OjRo02KDAAAWIW16n9ukADu2LFDVapUkSTt2bPH6ZzVHskGAADIDqYngD/88IPZIQAAAIuzWtHJ9ATwn37//XdJUqFChUyOBAAAWImXtfI/8x8CSU1N1ZAhQxQUFKTIyEhFRkYqODhYQ4cOVWpqqtnhAQAAZKs//vhDzz77rEJDQ+Xr66sKFSro559/ztIxTK8AvvHGG/rwww/11ltvKSYmRpK0Zs0axcXF6cqVKxo+fLjJEQIAAE/nLlPAZ86cUUxMjOrWravvvvtO+fLl0969exUSEpKl45ieAM6cOVNTp07VE0884WirWLGiChYsqC5dupAAAgAAyxg5cqQKFy6s6dOnO9qKFSuW5eOYPgV8+vRplS5dOk176dKldfr0aRMiAgAAVmOzue5ISkrS+fPnnY6kpKR04/jqq69UtWpVPf3008qfP78qV66sKVOmZPn7NT0BrFSpkt5///007e+//74qVapkQkQAAABZJz4+XkFBQU5HfHx8utceOHBAEyZMUKlSpfT999/r5ZdfVvfu3TVz5swsjclmGIaRpT1m0o8//qjHH39cRYoUUfXq1SVJ69ev15EjR/Ttt9+qZs2ame7zyrWsjhK4d4U6fmJ2CICT36e2NjsEwImPiQvTnp/ruq+mnfKfqDQVP7vdLrvdnuZab29vVa1aVevWrXO0de/eXZs2bdL69euzLCbTK4C1a9fWnj179OSTT+rs2bM6e/asWrRood27d99V8gcAAOBO7Ha7AgMDnY70kj9JCg8PV9myZZ3aypQpo8OHD2dpTKY/BCJJERERPOwBAABM4y77AMbExGj37t1ObXv27FFkZGSWjmNKArhtW8bLrBUrVnRhJAAAAO6zDUzPnj1Vo0YNjRgxQi1bttTGjRs1efJkTZ48OUvHMSUBjI6Ols1m052WH9psNqWkpGRTVAAAAOaqVq2aFixYoAEDBmjIkCEqVqyYxo4dq7Zt22bpOKYkgImJiWYMCwAAkC73qP9d16RJEzVp0sSlY5iSAGb1PDYAAAAy7q6eAl69erWeffZZVa9eXX/88Yckafbs2VqzZs1dBbF//3698sorql+/vurXr6/u3btr//79d9UXAABAZnnZbC473FGmE8B58+apUaNG8vX11ZYtWxz72pw7d04jRozIdADff/+9ypYtq40bN6pixYqqWLGiNmzYoHLlymnp0qWZ7g8AAAC3l+kp4GHDhmnixIl6/vnn9ckn/39j25iYGA0bNizTAfTv3189e/bUW2+9laa9X79+atCgQab7BAAAyAw3LdS5TKYrgLt371atWrXStAcFBens2bOZDmDXrl168cUX07S/8MIL+vXXXzPdHwAAAG4v0wlggQIFtG/fvjTta9asUfHixTMdQL58+ZSQkJCmPSEhQfnz5890fwAAAJlls9lcdrijTE8Bd+rUSa+++qqmTZsmm82mo0ePav369erdu7diY2MzHUCnTp3UuXNnHThwQDVq1JAkrV27ViNHjlSvXr0y3R8AAABuL9MJYP/+/ZWamqp69erp0qVLqlWrlux2u3r37q1XXnkl0wHExsYqICBA77zzjgYMGCDp+lfDxcXFqXv37pnuDwAAILPctFDnMjbjTl/HcQvJycnat2+fLly4oLJly8rf3/+eg/n7778lSQEBAffUz5Vr9xyK5X0yd45mTv9Qf/11UvdFlVb/12NVga/luyeFOn5y54twS/4+OdW/RQU9XqWQ8gbatf3QWb0x9xdtSTxtdmj/Wr9PbW12CP96/K7MWj6m7E583cvzXPfcwYT/lHVZ33frrvYBlCRvb2+VLVtWDzzwwD0lf4mJidq7d6+k64nfjeRv7969Onjw4F33i7u3+Ltv9faoeL3Upas++XyBoqJK6+WXXtSpU6fMDg0WNrbDA6pTroC6TP5Jtd5crJU7j2tenzoqEOxrdmiwKH5X4t8s0wlg3bp19cgjj9zyyKz27dtr3bp1ado3bNig9u3bZ7o/3LvZM6erxVMt1fzJ/6hEyZJ6c9Bg+fj4aOH8eWaHBovyyZVDTaoW0uDPErR+z0klnrigUQt3KPHEBXV4pKTZ4cGi+F3pWWw21x3uKNMJYHR0tCpVquQ4ypYtq+TkZP3yyy+qUKFCpgPYsmWLYmJi0rQ/9NBD6T4dDNe6mpysXb/u1EPVazjavLy89NBDNbRt6xYTI4OV5cxhU84cXrqSnOrUfjk5RQ/dl8+kqGBl/K7Ev12mZ9vHjBmTbntcXJwuXLiQ6QBsNptj7d8/nTt3TikpKZnuD/fmzNkzSklJUWhoqFN7aGioEhMPmBQVrO7ClWvauPcv9W5WTnuPndOJc0n6z0NFVK1kqBL/zPzvHeBe8bvS87jrdi2uctdrAG/27LPPatq0aZl+Xa1atRQfH++U7KWkpCg+Pl4PP/zwHV+flJSk8+fPOx03vp4OgOfoMvkn2STtGNtcR6c+rU4N7tP8nw4r9e6eYwMAS8uy523Wr18vHx+fTL9u5MiRqlWrlqKiolSzZk1J0urVq3X+/HmtWLHijq+Pj4/X4MGDndreiB2kNwfGZToWSCHBIcqRI0eaRcynTp1S3rx5TYoKkA6evKAn3lqh3N45FOCbS3+eu6KpL9fQoZMXzQ4NFsTvSs+TZRWxf4lMJ4AtWrRw+tkwDB07dkw///zzXW0EXbZsWW3btk3vv/++tm7dKl9fXz3//PPq1q2b8uTJc8fXDxgwIM2G0UYOe6bjwHW5vL1Vpmw5bfhpvR6pV1+SlJqaqg0b1qv1M8+aHB0gXUpO0aXkFAXlzqW6FQpo8KdbzQ4JFsTvSvzbZToBDAoKcvrZy8tLUVFRGjJkiBo2bHhXQURERGjEiBF39Vq73S673TnhYx/Ae/Ncuw6Kfb2fypUrr/IVKuqj2TN1+fJlNX+yxZ1fDLhI3fIFZLNJ+479rWJh/oprFa29x85r7hrWW8Ec/K70LFZbA5ipBDAlJUUdOnRQhQoVFBIScteDbtu2TeXLl5eXl5e2bdt222srsqFmtnu08WM6c/q0Pnj/Pf3110lFlS6jDyZNVSjTGjBRoG8uvfl0JUWE+OrsxWR9/fMRDZ+3XddSWAMIc/C70rN4WSv/y/w3gfj4+GjXrl0qVqzYXQ/q5eWl48ePK3/+/PLy8pLNZlN6Ydhstrt6EpgKINwR3wQCd8M3gcDdmPlNID2+/M1lfY9tVtplfd+tTH/U5cuX14EDB+4pAUxMTFS+fPkcfwcAADCT1SqAmU4Ahw0bpt69e2vo0KG6//775efn53Q+MDDwjn1ERkam+3cAAAC4Xoafeh4yZIguXryoxx57TFu3btUTTzyhQoUKKSQkRCEhIQoODr6rdYEzZ87UN9984/i5b9++Cg4OVo0aNXTo0KFM9wcAAJBZNpvNZYc7yvAawBw5cujYsWPatWvXba+rXbt2pgKIiorShAkT9Mgjj2j9+vWqV6+exo4dq0WLFilnzpyaP39+pvqTWAMI98QaQLgb1gDC3Zi5BvC1r3e7rO93mka5rO+7leGP+kaemNkE706OHDmikiWvf5n7woUL9dRTT6lz586KiYlRnTp1snQsAACA9FhtDWCmNr52RRnT39/fsZP6kiVL1KBBA0nXnza+fPlylo8HAABgdZkqtt533313TAJPnz6dqQAaNGigjh07qnLlytqzZ48ee+wxSdLOnTtVtGjRTPUFAABwN9x0qZ7LZCoBHDx4cJpvArlX48ePV2xsrA4fPqx58+YpNDRUkrR582Y988wzWToWAABAerwslgFmKgFs3bq18ufPn2WDX7t2Te+995769eunQoUKOZ0bPHhwlo0DAACA/y/DawBdsf4vZ86cGjVqlK5d47FdAABgHi8XHu4ow3Fl8hvjMqxevXr68ccfXdI3AAAA0srwFHBqaqpLAmjcuLH69++v7du3p/vNIk888YRLxgUAALjBYksAM/9VcFmtS5cukqTRo0enOWez2ZSSkpLdIQEAAHg00xNAV1UWAQAAMspqTwG71drEK1eumB0CAACAxzM9AUxJSdHQoUNVsGBB+fv768CBA5Kk2NhYffjhhyZHBwAArMBmc93hjkxPAIcPH64ZM2Zo1KhR8vb2drSXL19eU6dONTEyAABgFV421x3uyPQEcNasWZo8ebLatm2rHDlyONorVaqk3377zcTIAAAAPJPpD4H88ccfKlmyZJr21NRUXb161YSIAACA1fAQSDYrW7asVq9enab9iy++UOXKlU2ICAAAwLOZXgEcOHCg2rVrpz/++EOpqamaP3++du/erVmzZmnRokVmhwcAACzAYgVA8yuAzZo109dff61ly5bJz89PAwcO1K5du/T111+rQYMGZocHAADgcUyvAHbs2FHPPvusli5danYoAADAotz1aV1XMb0CePLkST366KMqXLiw+vbtq61bt5odEgAAgEczPQH88ssvdezYMcXGxmrjxo2qUqWKypUrpxEjRujgwYNmhwcAACzA5sI/7sj0BFCSQkJC1LlzZ61cuVKHDh1S+/btNXv27HS3hwEAAMhqbARtoqtXr+rnn3/Whg0bdPDgQYWFhZkdEgAAgMdxiwTwhx9+UKdOnRQWFqb27dsrMDBQixYt0u+//252aAAAwAKsVgE0/SngggUL6vTp03r00Uc1efJkNW3aVHa73eywAAAAPJbpCWBcXJyefvppBQcHmx0KAACwKJvFdoI2PQHs1KmT2SEAAABYiukJIAAAgNncda2eq7jFQyAAAADIPlQAAQCA5VlsCSAJIAAAgJfFMkCmgAEAACyGCiAAALA8HgIBAACAR6MCCAAALM9iSwCpAAIAAFgNFUAAAGB5XrJWCZAKIAAAgMVQAQQAAJZntTWAJIAAAMDy2AYGAAAAHo0KIAAAsDy+Cg4AAAAejQogAACwPIsVAKkAAgAAWA0VQAAAYHmsAQQAAIBHowIIAAAsz2IFQBJAAAAAq02JWu39AgAAWB4JIAAAsDybzeay41689dZbstls6tGjR9a80f9DAggAAOCGNm3apEmTJqlixYpZ3jcJIAAAsDybC4+7ceHCBbVt21ZTpkxRSEjIXfZyaySAAAAALpSUlKTz5887HUlJSbd9TdeuXfX444+rfv36LomJBBAAAFiel83msiM+Pl5BQUFOR3x8/C1j+eSTT/TLL7/c9pp7xTYwAAAALjRgwAD16tXLqc1ut6d77ZEjR/Tqq69q6dKl8vHxcVlMJIAAAMDyXLkPtN1uv2XCd7PNmzfrxIkTqlKliqMtJSVFq1at0vvvv6+kpCTlyJHjnmMiAQQAAJbnLt8EUq9ePW3fvt2prUOHDipdurT69euXJcmfRAIIAADgNgICAlS+fHmnNj8/P4WGhqZpvxckgAAAwPLudcPmfxsSQAAAADe2cuXKLO+TBBAAAFie1fbFs9r7BQAAsDwqgAAAwPKstgaQCiAAAIDFUAEEAACWZ636HxVAAAAAy6ECCAAALM9qawBJAIFs8vvU1maHADgJqdbN7BAAJ5e3vG/a2FabErXa+wUAALA8KoAAAMDyrDYFTAUQAADAYqgAAgAAy7NW/Y8KIAAAgOVQAQQAAJZnsSWAVAABAACshgogAACwPC+LrQIkAQQAAJbHFDAAAAA8GhVAAABgeTaLTQFTAQQAALAYKoAAAMDyWAMIAAAAj0YFEAAAWJ7VtoGhAggAAGAxVAABAIDlWW0NIAkgAACwPKslgEwBAwAAWAwVQAAAYHlsBA0AAACPRgUQAABYnpe1CoBUAAEAAKyGCiAAALA81gACAADAo1EBBAAAlme1fQBJAAEAgOUxBQwAAACPRgUQAABYHtvAAAAAwKNRAQQAAJbHGkAAAAB4NCqAAADA8qy2DQwVQAAAAIuhAggAACzPYgVAEkAAAAAvi80BMwUMAABgMVQAAQCA5Vmr/kcFEAAAwHKoAAIAAFisBEgFEAAAwGKoAAIAAMvjq+AAAADg0agAAgAAy7PYNoAkgAAAABbL/5gCBgAAsBoqgAAAABYrAVIBBAAAsBgqgAAAwPLYBgYAAAAezfQKYEpKisaMGaPPPvtMhw8fVnJystP506dPmxQZAACwCqttA2N6BXDw4MEaPXq0WrVqpXPnzqlXr15q0aKFvLy8FBcXZ3Z4AAAAHsf0BHDOnDmaMmWKXnvtNeXMmVPPPPOMpk6dqoEDB+qnn34yOzwAAGABNhce7sj0BPD48eOqUKGCJMnf31/nzp2TJDVp0kTffPONmaEBAACrsFgGaHoCWKhQIR07dkySVKJECS1ZskSStGnTJtntdjNDAwAA8EimJ4BPPvmkli9fLkl65ZVXFBsbq1KlSun555/XCy+8YHJ0AADACmwu/OOObIZhGGYH8U8//fST1q1bp1KlSqlp06Z31ceVa1kcFAB4oJBq3cwOAXByecv7po295dDfLuu7cmSAy/q+W6ZvA3Ozhx56SA899JDZYQAAAAthG5hsFh8fr2nTpqVpnzZtmkaOHGlCRAAAAJ7N9ARw0qRJKl26dJr2cuXKaeLEiSZEBAAArMZiDwGbnwAeP35c4eHhadrz5cvneDoYAAAAWcf0BLBw4cJau3Ztmva1a9cqIiLChIgAAIDlWKwEaPpDIJ06dVKPHj109epVPfLII5Kk5cuXq2/fvnrttddMjg4AAFiBu27X4iqmJ4B9+vTRqVOn1KVLFyUnJ0uSfHx81K9fPw0YMMDk6AAAADyP2+wDeOHCBe3atUu+vr4qVarUPX0LCPsAAsCdsQ8g3I2Z+wBu//2Cy/quUMjfZX3fLdPXAN7g7++vatWqqXz58nwFHAAAsKT4+HhVq1ZNAQEByp8/v5o3b67du3dn+TimTAG3aNFCM2bMUGBgoFq0aHHba+fPn59NUQEAAKtylxWAP/74o7p27apq1arp2rVrev3119WwYUP9+uuv8vPzy7JxTEkAg4KCZPu/LbeDgoLMCAEAAMDtLF682OnnGTNmKH/+/Nq8ebNq1aqVZeOYkgBOnz493b8DAACYwoUlwKSkJCUlJTm12e32DC15O3funCQpT548WRqT26wBBAAA8ETx8fEKCgpyOuLj4+/4utTUVPXo0UMxMTEqX758lsZkegL4559/6rnnnlNERIRy5sypHDlyOB0wxydz56hxg0dUrXIFtW39tLZv22Z2SAD3JUwTU6WEvhj7kg4sGa7LW95X0zoVnc43e6SSvv6gq37/YaQub3lfFe8raFKkuFs2F/4ZMGCAzp0753RkZKu7rl27aseOHfrkk0+y/P2avg9g+/btdfjwYcXGxio8PNyxNhDmWfzdt3p7VLzeHDRYFSpU0pzZM/XySy/qy0WLFRoaanZ4sCjuS5jJz9eu7Xv+0Kwv1+vT0Z3TnM/t6611Cfs1b+kvmjCwrQkRwp1ldLr3n7p166ZFixZp1apVKlSoUJbHZHoCuGbNGq1evVrR0dFmh4L/M3vmdLV4qqWaP/kfSdKbgwZr1aqVWjh/nl7slPYXH5AduC9hpiVrf9WStb/e8vzH32ySJBUJz9p1Wsg+7lJ/MgxDr7zyihYsWKCVK1eqWLFiLhnH9CngwoULy032ooakq8nJ2vXrTj1UvYajzcvLSw89VEPbtm4xMTJYGfclAFdzl68C7tq1qz766CPNnTtXAQEBOn78uI4fP67Lly/f4zt0ZnoCOHbsWPXv318HDx40OxRIOnP2jFJSUtJMqYWGhuqvv/4yKSpYHfclAKuYMGGCzp07pzp16ig8PNxxfPrpp1k6julTwK1atdKlS5dUokQJ5c6dW7ly5XI6f/r06du+Pr1Hq40cmZ9rBwAAFuZGU8DZwfQEcOzYsff0+vj4eA0ePNip7Y3YQXpzYNw99WtVIcEhypEjh06dOuXUfurUKeXNm9ekqGB13JcAkLVMTwDbtWt3T68fMGCAevXq5dRm5KD6d7dyeXurTNly2vDTej1Sr76k6/sQbdiwXq2fedbk6GBV3JcAXM3mLiXAbGJKAnj+/HkFBgY6/n47N667lfQerb5y7d7is7rn2nVQ7Ov9VK5ceZWvUFEfzZ6py5cvq/mTt//eZsCVuC9hJj9fb5UonM/xc9GCoap4X0GdOX9JR46fUUhgbhUuEKLw/Ne/3vS+omGSpD9Pndefp/42JWbgdkxJAENCQnTs2DHlz59fwcHB6e79ZxiGbDabUlJSTIjQ2h5t/JjOnD6tD95/T3/9dVJRpcvog0lTFcpUG0zEfQkzVSkbqSVTX3X8PKr39e2IZn/1kzoP+kiP166gKUOec5yfPfIFSdKwid9q+KRvszdY3BV32QYmu9gME/Zg+fHHHxUTE6OcOXPqxx9/vO21tWvXznT/VAAB4M5CqnUzOwTAyeUt75s29u7jl1zWd1SB3C7r+26ZUgH8Z1J3NwkeAABAVrJYAdD8h0C23eK7PG02m3x8fFSkSBG2dAEAAK5lsQzQ9AQwOjr6tt//mytXLrVq1UqTJk2Sj49PNkYGAADgmUz/JpAFCxaoVKlSmjx5shISEpSQkKDJkycrKipKc+fO1YcffqgVK1bozTffNDtUAADgoWwu/OOOTK8ADh8+XO+++64aNWrkaKtQoYIKFSqk2NhYbdy4UX5+fnrttdf09ttvmxgpAACAZzA9Ady+fbsiIyPTtEdGRmr79u2Srk8THzt2LLtDAwAAFmG1bWBMnwIuXbq03nrrLSUnJzvarl69qrfeekulS5eWJP3xxx8KCwszK0QAAACPYnoFcPz48XriiSdUqFAhVaxYUdL1qmBKSooWLVokSTpw4IC6dOliZpgAAMCDWawAaM5G0Df7+++/NWfOHO3Zs0eSFBUVpTZt2iggIOCu+mMjaAC4MzaChrsxcyPo/Scuu6zvEvl9Xdb33TK1Anj16lWVLl1aixYt0n//+18zQwEAAFZmsRKgqQlgrly5dOXKFTNDAAAAcNvtWlzF9IdAunbtqpEjR+raNeZtAQAAsoPpD4Fs2rRJy5cv15IlS1ShQgX5+fk5nZ8/f75JkQEAAKuw2jYwpieAwcHB+s9//mN2GAAAAJZhegI4ffp0s0MAAAAWZ7ECoPlrAAEAAJC9TKkAVqlSRcuXL1dISIgqV64s220m3n/55ZdsjAwAAFiSxUqApiSAzZo1k91ulyQ1b97cjBAAAAAsy5QEcNCgQY6/HzlyRG3btlXdunXNCAUAAIB9ALPbyZMn1bhxYxUuXFh9+/bV1q1bzQ4JAABYjM3musMdmZ4Afvnllzp27JhiY2O1ceNGValSReXKldOIESN08OBBs8MDAADwODbDMAyzg/in33//XR9//LGmTZumvXv33tU3hFzhS0UA4I5CqnUzOwTAyeUt75s29pHTSS7ru3Aeu8v6vlumVwD/6erVq/r555+1YcMGHTx4UGFhYWaHBAAA4HHcIgH84Ycf1KlTJ4WFhal9+/YKDAzUokWL9Pvvv5sdGgAAsACrrQE0/ZtAChYsqNOnT+vRRx/V5MmT1bRpU8cWMQAAAMh6pieAcXFxevrppxUcHGx2KAAAwLLctFTnIqYngJ06dTI7BAAAAEsxPQEEAAAwm7uu1XMVEkAAAGB5Fsv/3OMpYAAAAGQfKoAAAMDyrDYFTAUQAADAYqgAAgAAy7NZbBUgFUAAAACLoQIIAABgrQIgFUAAAACroQIIAAAsz2IFQBJAAAAAtoEBAACAR6MCCAAALI9tYAAAAODRqAACAABYqwBIBRAAAMBqqAACAADLs1gBkAogAACA1VABBAAAlme1fQBJAAEAgOWxDQwAAAA8GhVAAABgeVabAqYCCAAAYDEkgAAAABZDAggAAGAxrAEEAACWxxpAAAAAeDQqgAAAwPKstg8gCSAAALA8poABAADg0agAAgAAy7NYAZAKIAAAgNVQAQQAALBYCZAKIAAAgMVQAQQAAJZntW1gqAACAABYDBVAAABgeewDCAAAAI9GBRAAAFiexQqAJIAAAABWywCZAgYAALAYEkAAAGB5Nhf+uRvjx49X0aJF5ePjowcffFAbN27M0vdLAggAAOBGPv30U/Xq1UuDBg3SL7/8okqVKqlRo0Y6ceJElo1BAggAACzPZnPdkVmjR49Wp06d1KFDB5UtW1YTJ05U7ty5NW3atCx7vySAAAAALpSUlKTz5887HUlJSelem5ycrM2bN6t+/fqONi8vL9WvX1/r16/Pspg88ilgH498V9kvKSlJ8fHxGjBggOx2u9nhANyTWezylvfNDsEjcF96BlfmDnHD4jV48GCntkGDBikuLi7NtX/99ZdSUlIUFhbm1B4WFqbffvsty2KyGYZhZFlv8Cjnz59XUFCQzp07p8DAQLPDAbgn4Za4L3EnSUlJaSp+drs93f9hOHr0qAoWLKh169apevXqjva+ffvqxx9/1IYNG7IkJmplAAAALnSrZC89efPmVY4cOfTnn386tf/5558qUKBAlsXEGkAAAAA34e3trfvvv1/Lly93tKWmpmr58uVOFcF7RQUQAADAjfTq1Uvt2rVT1apV9cADD2js2LG6ePGiOnTokGVjkADilux2uwYNGsSiZrgN7km4I+5LZLVWrVrp5MmTGjhwoI4fP67o6GgtXrw4zYMh94KHQAAAACyGNYAAAAAWQwIIAABgMSSAAAAAFkMCCMCtHTx4UDabTQkJCW7ZH/5d4uLiFB0dfc/9rFy5UjabTWfPns3wa9q3b6/mzZvf89hAVuAhEOjgwYMqVqyYtmzZkiW/GIGslJKSopMnTypv3rzKmfPeNy7gfre2CxcuKCkpSaGhoffUT3Jysk6fPq2wsDDZbLYMvebcuXMyDEPBwcH3NDaQFdgGBoCprl69qly5ct3yfI4cObJ09/uskJycLG9vb7PDwF3w9/eXv7//Lc9n9L+tt7d3pu/LoKCgTF0PuBJTwB7kiy++UIUKFeTr66vQ0FDVr19fFy9elCRNnTpVZcqUkY+Pj0qXLq0PPvjA8bpixYpJkipXriybzaY6depIur7z+JAhQ1SoUCHZ7XbHPkQ3JCcnq1u3bgoPD5ePj48iIyMVHx/vOD969GhVqFBBfn5+Kly4sLp06aILFy5kwycBV5k8ebIiIiKUmprq1N6sWTO98MILkqQvv/xSVapUkY+Pj4oXL67Bgwfr2rVrjmttNpsmTJigJ554Qn5+fho+fLjOnDmjtm3bKl++fPL19VWpUqU0ffp0SelP2e7cuVNNmjRRYGCgAgICVLNmTe3fv1/Sne/b9Pz444964IEHZLfbFR4erv79+zvFXKdOHXXr1k09evRQ3rx51ahRo3v6HOE6d7pHb54CvjEtO3z4cEVERCgqKkqStG7dOkVHR8vHx0dVq1bVwoULne7Dm6eAZ8yYoeDgYH3//fcqU6aM/P399eijj+rYsWNpxrohNTVVo0aNUsmSJWW321WkSBENHz7ccb5fv3667777lDt3bhUvXlyxsbG6evVq1n5gsC4DHuHo0aNGzpw5jdGjRxuJiYnGtm3bjPHjxxt///238dFHHxnh4eHGvHnzjAMHDhjz5s0z8uTJY8yYMcMwDMPYuHGjIclYtmyZcezYMePUqVOGYRjG6NGjjcDAQOPjjz82fvvtN6Nv375Grly5jD179hiGYRj/+9//jMKFCxurVq0yDh48aKxevdqYO3euI6YxY8YYK1asMBITE43ly5cbUVFRxssvv5z9Hw6yzOnTpw1vb29j2bJljrZTp0452latWmUEBgYaM2bMMPbv328sWbLEKFq0qBEXF+e4XpKRP39+Y9q0acb+/fuNQ4cOGV27djWio6ONTZs2GYmJicbSpUuNr776yjAMw0hMTDQkGVu2bDEMwzB+//13I0+ePEaLFi2MTZs2Gbt37zamTZtm/Pbbb4Zh3Pm+Ta+/3LlzG126dDF27dplLFiwwMibN68xaNAgR8y1a9c2/P39jT59+hi//fabYyy4nzvdo4MGDTIqVarkONeuXTvD39/feO6554wdO3YYO3bsMM6dO2fkyZPHePbZZ42dO3ca3377rXHfffc53Tc//PCDIck4c+aMYRiGMX36dCNXrlxG/fr1jU2bNhmbN282ypQpY7Rp08ZprGbNmjl+7tu3rxESEmLMmDHD2Ldvn7F69WpjypQpjvNDhw411q5dayQmJhpfffWVERYWZowcOdIlnxushwTQQ2zevNmQZBw8eDDNuRIlSjglZoZx/RdL9erVDcNI+w/iDREREcbw4cOd2qpVq2Z06dLFMAzDeOWVV4xHHnnESE1NzVCMn3/+uREaGprRtwQ31axZM+OFF15w/Dxp0iQjIiLCSElJMerVq2eMGDHC6frZs2cb4eHhjp8lGT169HC6pmnTpkaHDh3SHe/m+3PAgAFGsWLFjOTk5HSvv9N9e3N/r7/+uhEVFeV0H48fP97w9/c3UlJSDMO4ngBWrlz5Vh8J3Mzt7tH0EsCwsDAjKSnJ0TZhwgQjNDTUuHz5sqNtypQpd0wAJRn79u1zvGb8+PFGWFiY01g3EsDz588bdrvdKeG7k//973/G/fffn+HrgdthCthDVKpUSfXq1VOFChX09NNPa8qUKTpz5owuXryo/fv368UXX3SsffH399ewYcMcU2bpOX/+vI4ePaqYmBin9piYGO3atUvS9emMhIQERUVFqXv37lqyZInTtcuWLVO9evVUsGBBBQQE6LnnntOpU6d06dKlrP8AkG3atm2refPmKSkpSZI0Z84ctW7dWl5eXtq6dauGDBnidK916tRJx44dc/rvXrVqVac+X375ZX3yySeKjo5W3759tW7duluOn5CQoJo1a6a7bjAj9+3Ndu3aperVqzst5I+JidGFCxf0+++/O9ruv//+23wqcCe3u0fTU6FCBad1f7t371bFihXl4+PjaHvggQfuOG7u3LlVokQJx8/h4eE6ceJEutfu2rVLSUlJqlev3i37+/TTTxUTE6MCBQrI399fb775pg4fPnzHOICMIAH0EDly5NDSpUv13XffqWzZsho3bpyioqK0Y8cOSdKUKVOUkJDgOHbs2KGffvrpnsasUqWKEhMTNXToUF2+fFktW7bUU089Jen6uq0mTZqoYsWKmjdvnjZv3qzx48dLur52EP9eTZs2lWEY+uabb3TkyBGtXr1abdu2lXT9CcvBgwc73Wvbt2/X3r17nf4x9fPzc+qzcePGOnTokHr27KmjR4+qXr166t27d7rj+/r6uu7N3cbNMcN93e4eTU9W/be9+X9KbDabjFtstHGn+3j9+vVq27atHnvsMS1atEhbtmzRG2+8we9PZBkSQA9is9kUExOjwYMHa8uWLfL29tbatWsVERGhAwcOqGTJkk7HjYc/bvyfb0pKiqOvwMBARUREaO3atU5jrF27VmXLlnW6rlWrVpoyZYo+/fRTzZs3T6dPn9bmzZuVmpqqd955Rw899JDuu+8+HT16NBs+Bbiaj4+PWrRooTlz5ujjjz9WVFSUqlSpIun6/xTs3r07zb1WsmTJW1ZfbsiXL5/atWunjz76SGPHjtXkyZPTva5ixYpavXp1uovhM3rf/lOZMmW0fv16p3+o165dq4CAABUqVOi2McM93e4ezYioqCht377dUUGUpE2bNmVpjKVKlZKvr6+WL1+e7vl169YpMjJSb7zxhqpWrapSpUrp0KFDWRoDrI1tYDzEhg0btHz5cjVs2FD58+fXhg0bdPLkSZUpU0aDBw9W9+7dFRQUpEcffVRJSUn6+eefdebMGfXq1Uv58+eXr6+vFi9erEKFCsnHx0dBQUHq06ePBg0apBIlSig6OlrTp09XQkKC5syZI+n6U77h4eGqXLmyvLy89Pnnn6tAgQIKDg5WyZIldfXqVY0bN05NmzbV2rVrNXHiRJM/JWSVtm3bqkmTJtq5c6eeffZZR/vAgQPVpEkTFSlSRE899ZRjWnjHjh0aNmzYLfsbOHCg7r//fpUrV05JSUlatGiRypQpk+613bp107hx49S6dWsNGDBAQUFB+umnn/TAAw8oKirqjvftzbp06aKxY8fqlVdeUbdu3bR7924NGjRIvXr1umPSCvd1q3s0I9q0aaM33nhDnTt3Vv/+/XX48GG9/fbbkpThPf/uxMfHR/369VPfvn3l7e2tmJgYnTx5Ujt37tSLL76oUqVK6fDhw/rkk09UrVo1ffPNN1qwYEGWjA1I4ilgT/Hrr78ajRo1MvLly2fY7XbjvvvuM8aNG+c4P2fOHCM6Otrw9vY2QkJCjFq1ahnz5893nJ8yZYpRuHBhw8vLy6hdu7ZhGIaRkpJixMXFGQULFjRy5cplVKpUyfjuu+8cr5k8ebIRHR1t+Pn5GYGBgUa9evWMX375xXF+9OjRRnh4uOHr62s0atTImDVrltOiafx7paSkGOHh4YYkY//+/U7nFi9ebNSoUcPw9fU1AgMDjQceeMCYPHmy47wkY8GCBU6vGTp0qFGmTBnD19fXyJMnj9GsWTPjwIEDhmGk/5DS1q1bjYYNGxq5c+c2AgICjJo1azriuNN9m15/K1euNKpVq2Z4e3sbBQoUMPr162dcvXrVcb527drGq6++eo+fGrLTre7R9B4C+eeTuTesXbvWqFixouHt7W3cf//9xty5cw1JjifA03sIJCgoyKmPBQsWGP/8Z/bmsVJSUoxhw4YZkZGRRq5cuYwiRYo4PUTVp08fIzQ01PD39zdatWpljBkzJs0YwN3im0AAALiDOXPmqEOHDjp37pxp61CBrMQUMAAAN5k1a5aKFy+uggULauvWrerXr59atmxJ8gePQQIIAMBNjh8/roEDB+r48eMKDw/X008/7fQtHcC/HVPAAAAAFsMjbgAAABZDAggAAGAxJIAAAAAWQwIIAABgMSSAAAAAFkMCCMBttW/fXs2bN3f8XKdOHfXo0SPb41i5cqVsNpvOnj2b7WMDgCuQAALItPbt28tms8lms8nb21slS5bUkCFDdO3aNZeOO3/+fA0dOjRD15K0AcCtsRE0gLvy6KOPavr06UpKStK3336rrl27KleuXBowYIDTdcnJyfL29s6SMfPkyZMl/QCA1VEBBHBX7Ha7ChQooMjISL388suqX7++vvrqK8e07fDhwxUREaGoqChJ0pEjR9SyZUsFBwcrT548atasmQ4ePOjoLyUlRb169VJwcLBCQ0PVt29f3bxP/c1TwElJSerXr58KFy4su92ukiVL6sMPP9TBgwdVt25dSVJISIhsNpvat28vSUpNTVV8fLyKFSsmX19fVapUSV988YXTON9++63uu+8++fr6qm7duk5xAoAnIAEEkCV8fX2VnJwsSVq+fLl2796tpUuXatGiRbp69aoaNWqkgIAArV69WmvXrpW/v78effRRx2veeecdzZgxQ9OmTdOaNWt0+vRpLViw4LZjPv/88/r444/13nvvadeuXZo0aZL8/f1VuHBhzZs3T5K0e/duHTt2TO+++64kKT4+XrNmzdLEiRO1c+dO9ezZU88++6x+/PFHSdcT1RYtWqhp06ZKSEhQx44d1b9/f1d9bABgCqaAAdwTwzC0fPlyff/993rllVd08uRJ+fn5aerUqY6p348++kipqamaOnWqbDabJGn69OkKDg7WypUr1bBhQ40dO1YDBgxQixYtJEkTJ07U999/f8tx9+zZo88++0xLly5V/fr1JUnFixd3nL8xXZw/f34FBwdLul4xHDFihJYtW6bq1as7XrNmzRpNmjRJtWvX1oQJE1SiRAm98847kqSoqCht375dI0eOzMJPDQDMRQII4K4sWrRI/v7+unr1qlJTU9WmTRvFxcWpa9euqlChgtO6v61bt2rfvn0KCAhw6uPKlSvav3+/zp07p2PHjunBBx90nMuZM6eqVq2aZhr4hoSEBOXIkUO1a9fOcMz79u3TpUuX1KBBA6f25ORkVa5cWZK0a9cupzgkOZJFAPAUJIAA7krdunU1YcIEeXt7KyIiQjlz/v9fJ35+fk7XXrhwQffff7/mzJmTpp98+fLd1fi+vr6Zfs2FCxckSd98840KFizodM5ut99VHADwb0QCCOCu+Pn5qWTJkhm6tkqVKvr000+VP39+BQYGpntNeHi4NmzYoFq1akmSrl27ps2bN6tKlSrpXl+hQgWlpqbqxx9/dEwB/9ONCmRKSoqjrWzZsrLb7Tp8+PAtK4dlypTRV1995dT2008/3flNAsC/CA+BAHC5tm3bKm/evGrWrJlWr16txMRErVy5Ut27d9fvv/8uSXr11Vf11ltvaeHChfrtt9/UpUuX2+7hV7RoUbVr104vvPCCFi5c6Ojzs88+kyRFRkbKZrNp0aJFOnnypC5cuKCAgAD17t1bPXv21MyZM7V//3798ssvGjdunGbOnClJ+u9//6u9e/eqT58+2r17t+bOnasZM2a4+iMCgGxFAgjA5XLnzq1Vq1apSJEiatGihcqUKaMXX3xRV65ccVQEX3vtNT333HNq166dqlevroCAAD355JO37XfChAl66qmn1KVLF5UuXVqdOnXSxYsXJUkFCxbU4MGD1b9/f4WFhalbt26SpKFDhyo2Nlbx8fEqU6aMHn30UX3zzTcqVqyYJKlIkSKaN2+eFi5cqEqVKmnixIkaMWKECz8dAMh+NuNWK6wBAADgkagAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYDAkgAACAxZAAAgAAWAwJIAAAgMWQAAIAAFgMCSAAAIDFkAACAABYzP8DO51goBMCb6AAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pHNUkQ3zWD6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30. Write a Python program to train a Decision Tree Classifier and use GridSearchCV to find the optimal values for max_depth and min_samples_split.\n",
        "Approach: Use GridSearchCV to tune max_depth and min_samples_split for DecisionTreeClassifier."
      ],
      "metadata": {
        "id": "9fgpkaLjWGXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 3, 5, 7, 10],\n",
        "    'min_samples_split': [2, 5, 10, 20]\n",
        "}\n",
        "\n",
        "# Train Decision Tree with GridSearchCV\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and score\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.2f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "best_dt = grid_search.best_estimator_\n",
        "y_pred = best_dt.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Set Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RlGfxTQWGqe",
        "outputId": "82bccd0e-39f1-4aab-c2c7-7fb3aea4deb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2}\n",
            "Best Cross-Validation Score: 0.94\n",
            "Test Set Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RIUmuNEpWIVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y_KIFUN6WKnN"
      }
    }
  ]
}