{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1.Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where\n",
        "multiprocessing is a better choice**"
      ],
      "metadata": {
        "id": "R84pifuknYRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multithreading and multiprocessing are two parallel computing strategies that can be leveraged to improve performance in different scenarios. Their applicability depends primarily on the nature of the task and the resources available. Here’s a breakdown of scenarios where each is preferable:"
      ],
      "metadata": {
        "id": "xvL61fX9nfNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When Multithreading is Preferable\n",
        "\n",
        "Multithreading is ideal in scenarios where tasks are:\n",
        "\n",
        "1.I/O-Bound Operations:\n",
        "\n",
        ".Scenario: Reading from disk files, waiting for network requests, or performing database queries.\n",
        "\n",
        ".Reason: Threads can be suspended while waiting for I/O operations to complete, allowing other threads to run in the meantime, which leads to higher efficiency without needing separate memory space for each thread."
      ],
      "metadata": {
        "id": "sXzi1h3SnjHb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Shared Memory and State:\n",
        "\n",
        ".Scenario: Real-time data processing, GUI applications, or applications where threads need to frequently access and update shared memory (e.g., progress updates in an application).\n",
        "\n",
        ".Reason: Threads within a process share the same memory space, making it easier to coordinate and pass data between threads than between separate processes, which require inter-process communication (IPC) mechanisms."
      ],
      "metadata": {
        "id": "o8tE7fwZn0_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Low CPU-Intensity or Light Computation:\n",
        "\n",
        ".Scenario: Tasks such as background logging, status updates, or short tasks where the CPU load is minimal.\n",
        "\n",
        ".Reason: The overhead of creating and managing threads is low, making it efficient for applications with light workloads that benefit from concurrency rather than full parallel execution."
      ],
      "metadata": {
        "id": "ehHBO67bn8yL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Fast Context Switching Needs:\n",
        "\n",
        ".Scenario: Applications requiring frequent switching between tasks, like web servers handling many short-lived, concurrent requests.\n",
        "\n",
        ".Reason: Threads have lower memory and context-switching overhead compared to processes, making them more suitable for applications needing rapid response to many concurrent tasks."
      ],
      "metadata": {
        "id": "yq2aOA7doF9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When Multiprocessing is Preferable\n",
        "\n",
        "Multiprocessing is more suitable for scenarios where tasks are:\n",
        "\n",
        "\n",
        "1.CPU-Bound Operations:\n",
        "\n",
        ".Scenario: Computationally intensive tasks such as mathematical simulations, data processing algorithms (e.g., machine learning model training), or large-scale data transformations.\n",
        "\n",
        ".Reason: Each process can run on a separate CPU core, allowing true parallelism on multicore processors, which is essential for CPU-bound tasks as it bypasses the Global Interpreter Lock (GIL) in languages like Python."
      ],
      "metadata": {
        "id": "6wpbaGsPoRpz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Independent, High-Resource Tasks:\n",
        "\n",
        ".Scenario: Tasks that require significant CPU time, memory, or resources and don’t need to share data continuously, such as independent data analysis on different data partitions or independent microservices.\n",
        "\n",
        ".Reason: Processes are isolated and have their own memory space, which prevents memory leaks or conflicts, allowing each task to maximize available resources.\n"
      ],
      "metadata": {
        "id": "ksV_T01woflz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Fault Isolation Needs:\n",
        "\n",
        ".Scenario: Applications where a failure in one task should not impact others, such as in certain high-availability systems or microservice-based architectures.\n",
        "\n",
        ".Reason: Each process runs independently. If one crashes, it won’t affect others, which is not the case with multithreading where a fault in one thread may impact the entire process."
      ],
      "metadata": {
        "id": "2rW7Qo3GosQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Security and Stability Requirements:\n",
        "\n",
        ".Scenario: Systems needing strong security boundaries (like financial processing systems or data isolation), where sensitive data handled by one task shouldn’t be accessible to another.\n",
        "\n",
        ".Reason: Separate memory spaces mean that each process has a clear boundary, reducing the risk of accidental or malicious data access."
      ],
      "metadata": {
        "id": "7OW7aVZ0o4yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Describe what a process pool is and how it helps in managing multiple processes efficiently**"
      ],
      "metadata": {
        "id": "7gd8gamYpBwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a collection of worker processes managed by a pool manager, which allows multiple tasks to be distributed across these processes in an efficient, controlled way. Rather than creating and destroying a process for each task, which can be time-consuming and resource-intensive, a process pool reuses a fixed number of processes to handle multiple tasks."
      ],
      "metadata": {
        "id": "9ws-K41ApFTw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key Characteristics and Advantages of a Process Pool\n",
        "\n",
        "1.Efficient Process Management:\n",
        "\n",
        "\n",
        ".Creating and terminating processes repeatedly is costly in terms of both time and memory. A process pool avoids this by creating a fixed number of processes once, at the start. These processes remain active and ready to handle tasks, which reduces the overhead associated with process creation and destruction."
      ],
      "metadata": {
        "id": "FDVeAKoGpKaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Task Distribution and Load Balancing:\n",
        "\n",
        "The process pool manager assigns tasks to available processes in the pool, distributing the workload evenly. Once a process completes a task, it becomes available for new tasks, optimizing CPU usage and reducing idle time"
      ],
      "metadata": {
        "id": "EeZ75wrKpRyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Concurrency and Parallelism:\n",
        "\n",
        "By leveraging multiple processes, each capable of running on a separate CPU core, process pools enable true parallelism for CPU-bound tasks. This is especially useful in multi-core systems where different cores can handle different processes simultaneously"
      ],
      "metadata": {
        "id": "Hn4a5MR1pWiA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Simplified Code and Maintenance:\n",
        "\n",
        "With a process pool, developers can manage multiple tasks concurrently without manually handling each process. The pool handles the details of managing the worker processes, including task scheduling and process lifecycle management. This makes code simpler and easier to maintain."
      ],
      "metadata": {
        "id": "3Zdg1Te9pcA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How a Process Pool Works\n",
        "\n",
        "Initialization:\n",
        "\n",
        " A fixed number of processes are created and maintained throughout the pool’s lifetime, typically determined based on the number of available CPU cores or the workload requirements.\n",
        "\n",
        "Task Submission:\n",
        "\n",
        "Tasks are submitted to the pool as jobs or tasks, and the pool manager assigns each task to an available process. Tasks can be submitted individually, or in bulk through methods like map, which maps each item in a collection to a process in the pool.\n",
        "\n",
        "Task Execution:\n",
        "\n",
        "Each process in the pool picks up a task and runs it to completion. Once a task is completed, the process is marked as available for the next task. This “recycling” of processes allows the pool to handle numerous tasks without the need for excessive process creation and termination.\n",
        "\n",
        "Termination:\n",
        "\n",
        "After all tasks are completed, the pool can be terminated, which stops all worker processes and frees up resources. This is particularly useful in long-running applications or batch processing tasks where the pool is only needed temporarily."
      ],
      "metadata": {
        "id": "5CWTZUZnpidv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool with 4 worker processes\n",
        "    with Pool(processes=4) as pool:\n",
        "        # Map a list of numbers to the square function\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "    print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teGwFaESpwmg",
        "outputId": "eb281532-0cf4-4411-8f9f-163233f77d97"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.Explain what multiprocessing is and why it is used in Python programs.**"
      ],
      "metadata": {
        "id": "xxT5TEq_p8dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing is a parallel programming technique that involves using multiple processes to perform tasks simultaneously, allowing programs to execute code across multiple CPU cores. Each process in multiprocessing runs independently with its own memory space, which helps overcome the limitations of the Global Interpreter Lock (GIL) in Python, enabling true parallel execution."
      ],
      "metadata": {
        "id": "k0XamGV7qGQo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why Multiprocessing is Used in Python Programs\n",
        "\n",
        "1.Bypassing the Global Interpreter Lock (GIL):\n",
        "\n",
        ".Python’s GIL restricts the interpreter to executing only one thread at a time within a single process, even on multi-core processors. This limits the effectiveness of multithreading for CPU-bound tasks.\n",
        "\n",
        ".Multiprocessing, however, creates separate processes, each with its own Python interpreter and memory space. This allows multiple processes to run concurrently, utilizing multiple CPU cores effectively and achieving true parallelism.\n",
        "\n",
        "2.Optimizing CPU-Bound Tasks:\n",
        "\n",
        ".For tasks that require significant computation (e.g., data processing, numerical simulations, or machine learning model training), multiprocessing allows Python to fully utilize multi-core systems.\n",
        "\n",
        ".Each process can independently execute a part of the task on a different CPU core, reducing the overall computation time compared to running sequentially in a single process.\n",
        "\n",
        "4.Isolated Memory Space:\n",
        "\n",
        ".Each process in multiprocessing has its own memory space, unlike threads that share memory within a single process. This isolation provides additional stability and security, as one process crashing or misbehaving will not directly affect other processes or corrupt shared data.\n",
        "\n",
        ".This makes multiprocessing particularly useful in tasks that require fault tolerance or isolation, such as processing data in parallel with potential for unpredictable failures.\n",
        "\n",
        "5.Improved Performance in I/O-Bound Tasks with Heavy Computation:\n",
        "\n",
        ".While multithreading is often suitable for I/O-bound tasks, multiprocessing is useful when I/O operations are interspersed with CPU-intensive computations, such as reading large files, performing transformations, and writing results.\n",
        "\n",
        ".In such cases, multiprocessing allows both I/O operations and CPU-bound operations to occur in parallel, leveraging both I/O and CPU cores effectively.\n",
        "\n",
        "6.Efficient Parallel Processing in Data-Intensive Applications:\n",
        "\n",
        ".Data-heavy applications, like data preprocessing pipelines, image or video processing, and data science tasks, often benefit significantly from multiprocessing.\n",
        "\n",
        ".Large datasets can be split into smaller chunks and processed in parallel, reducing the time needed for data transformation, analysis, or model training. For example, multiprocessing can help process images, apply transformations, or calculate complex statistics across multiple files or records simultaneously."
      ],
      "metadata": {
        "id": "elO8DZcpqQnu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Multiprocessing is Used in Python\n",
        "\n",
        "The multiprocessing library in Python provides a variety of constructs to facilitate multiprocessing, including:\n",
        "\n",
        "\n",
        ".Process: The basic unit of work, where each Process object represents an independent task.\n",
        "\n",
        ".Pool: A convenient way to manage multiple worker processes, which can handle a set number of tasks at once, automatically recycling processes as tasks complete.\n",
        "\n",
        ".Queue: For inter-process communication, allowing processes to share results or data safely.\n",
        "\n",
        ".Shared Memory (e.g., Value, Array): Used when limited sharing of data between processes is needed without excessive overhead."
      ],
      "metadata": {
        "id": "HUknbHhFrCKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(number):\n",
        "    return number * number\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a pool of worker processes\n",
        "    with Pool(processes=4) as pool:\n",
        "        # Apply the square function to each element in the list in parallel\n",
        "        results = pool.map(square, range(1000000))\n",
        "    print(results[:10])  # Display the first 10 results for verification"
      ],
      "metadata": {
        "id": "sezLh74grTMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Write a Python program using multithreading where one thread adds numbers to a list, and another\n",
        "thread removes numbers from the list. Implement a mechanism to avoid race conditions using\n",
        "threading.Lock.**"
      ],
      "metadata": {
        "id": "zU0zZ6PmrZNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a Python program that demonstrates multithreading, where one thread adds numbers to a shared list and another thread removes numbers from it. To avoid race conditions, the program uses a threading.Lock to ensure that only one thread can access or modify the list at a time."
      ],
      "metadata": {
        "id": "Uj86cvv3rde7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Shared list\n",
        "shared_list = []\n",
        "\n",
        "# Lock to avoid race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function for adding numbers to the list\n",
        "def add_to_list():\n",
        "    for i in range(10):\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            num = random.randint(1, 100)\n",
        "            shared_list.append(num)\n",
        "            print(f\"Added {num} to list\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate work with a random delay\n",
        "\n",
        "# Function for removing numbers from the list\n",
        "def remove_from_list():\n",
        "    for i in range(10):\n",
        "        with list_lock:  # Acquire the lock before modifying the list\n",
        "            if shared_list:\n",
        "                removed_num = shared_list.pop(0)\n",
        "                print(f\"Removed {removed_num} from list\")\n",
        "            else:\n",
        "                print(\"List is empty, nothing to remove\")\n",
        "        time.sleep(random.uniform(0.1, 0.5))  # Simulate work with a random delay\n",
        "\n",
        "# Create threads\n",
        "add_thread = threading.Thread(target=add_to_list)\n",
        "remove_thread = threading.Thread(target=remove_from_list)\n",
        "\n",
        "# Start threads\n",
        "add_thread.start()\n",
        "remove_thread.start()\n",
        "\n",
        "# Wait for both threads to complete\n",
        "add_thread.join()\n",
        "remove_thread.join()\n",
        "\n",
        "# Print the final state of the shared list\n",
        "print(f\"Final list contents: {shared_list}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY-9LRairjSD",
        "outputId": "3cc862c2-21c8-4e8e-cb59-406b6dbfcef7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added 41 to list\n",
            "Removed 41 from list\n",
            "List is empty, nothing to remove\n",
            "List is empty, nothing to remove\n",
            "Added 94 to list\n",
            "Added 14 to list\n",
            "Removed 94 from list\n",
            "Removed 14 from list\n",
            "Added 64 to list\n",
            "Removed 64 from list\n",
            "Added 91 to list\n",
            "Removed 91 from list\n",
            "Added 72 to list\n",
            "Removed 72 from list\n",
            "Added 29 to list\n",
            "Added 44 to list\n",
            "Removed 29 from list\n",
            "Removed 44 from list\n",
            "Added 42 to list\n",
            "Added 10 to list\n",
            "Final list contents: [42, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Describe the methods and tools available in Python for safely sharing data between threads and\n",
        "processes.**"
      ],
      "metadata": {
        "id": "3dX6v4HTruZz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python provides various methods and tools to safely share data between threads and processes, each suited to different use cases. Here’s an overview of key options available for both multithreading and multiprocessing:"
      ],
      "metadata": {
        "id": "6nyuiqqbr1FV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Sharing Data Between Threads\n",
        "\n",
        "Since threads run within the same memory space of a single process, they can directly access shared variables. However, to avoid race conditions, synchronization mechanisms are needed to ensure thread-safe operations.\n",
        "\n",
        "\n",
        "a. Locks (threading.Lock)\n",
        "\n",
        ".Description: A Lock is the most basic synchronization primitive in threading. It allows only one thread at a time to hold the lock and access shared resources, thus preventing race conditions.\n",
        "\n",
        ".Use Case: Ideal for protecting access to simple shared data structures like lists or dictionaries.\n"
      ],
      "metadata": {
        "id": "IlTDYBewr5yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "shared_data = []\n",
        "\n",
        "def safe_append(value):\n",
        "    with lock:  # Acquire lock to ensure only one thread modifies the list at a time\n",
        "        shared_data.append(value)"
      ],
      "metadata": {
        "id": "aYhzuUPRsF3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. RLock (threading.RLock)\n",
        "\n",
        "Description: A reentrant lock that allows a thread to acquire the lock multiple times without causing a deadlock.\n",
        "\n",
        "Use Case: Useful when a single thread needs to acquire the lock in nested functions or recursive calls."
      ],
      "metadata": {
        "id": "jqgHaQVGsFWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rlock = threading.RLock()"
      ],
      "metadata": {
        "id": "CitCmNE3sZTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Condition (threading.Condition)\n",
        "\n",
        "Description: A condition variable that allows threads to wait until a certain condition is met. Condition variables are often used with locks to synchronize threads.\n",
        "\n",
        "Use Case: Ideal for cases where threads need to wait for a specific state before proceeding, such as a producer-consumer scenario."
      ],
      "metadata": {
        "id": "xryDNu22sXVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition = threading.Condition()"
      ],
      "metadata": {
        "id": "gou2XlOIs_7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Queue (queue.Queue)\n",
        "\n",
        "Description: A thread-safe queue for exchanging data between threads. The Queue class handles locking and provides safe, FIFO access to shared data.\n",
        "\n",
        "Use Case: Useful for producer-consumer models or when multiple threads need to share data in a controlled way.\n"
      ],
      "metadata": {
        "id": "dqUC5PpgtCyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import Queue\n",
        "\n",
        "queue = Queue()\n",
        "queue.put(1)  # Add an item to the queue\n",
        "value = queue.get()  # Safely retrieve an item"
      ],
      "metadata": {
        "id": "_deG-1WhtKs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Sharing Data Between Processes\n",
        "\n",
        "Each process in Python has its own memory space, so data can’t be directly shared. Instead, inter-process communication (IPC) mechanisms are used to enable data sharing between processes.\n",
        "\n",
        "a. Queue (multiprocessing.Queue)\n",
        "\n",
        "Description: Similar to queue.Queue but specifically designed for use with multiple processes. It provides thread-safe, FIFO access to data across processes.\n",
        "Use Case: Ideal for producer-consumer patterns across processes, where one process adds data to the queue and another retrieves it"
      ],
      "metadata": {
        "id": "eRX4DsMotOI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Process, Queue\n",
        "\n",
        "queue = Queue()\n",
        "queue.put(1)"
      ],
      "metadata": {
        "id": "rMzprAwLtSzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Pipe (multiprocessing.Pipe)\n",
        "\n",
        "Description: Provides a two-way communication channel between processes with two ends (one for each process). Data sent through one end of the pipe is received by the other.\n",
        "\n",
        "Use Case: Suitable for scenarios where two processes need to communicate directly and frequently"
      ],
      "metadata": {
        "id": "z3Cw8HeFtWSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pipe\n",
        "\n",
        "parent_conn, child_conn = Pipe()\n",
        "parent_conn.send(\"Hello from parent\")\n",
        "message = child_conn.recv()"
      ],
      "metadata": {
        "id": "ekk8WnOktZ1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Shared Memory (multiprocessing.Value and multiprocessing.Array)\n",
        "\n",
        "Description: Provides shared memory locations (a single value or an array of values) that can be accessed by multiple processes.\n",
        "\n",
        "Use Case: Useful for sharing simple data types, like counters or small arrays, across processes without the overhead of a queue or pipe."
      ],
      "metadata": {
        "id": "r4xSx_1jtyWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Value, Array\n",
        "\n",
        "shared_counter = Value('i', 0)  # An integer shared value\n",
        "shared_array = Array('d', [0.1, 0.2, 0.3])  # An array of doubles"
      ],
      "metadata": {
        "id": "-QWASsaEt2p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Manager (multiprocessing.Manager)\n",
        "\n",
        "Description: Allows the creation of shared objects (e.g., lists, dictionaries) that can be accessed by multiple processes.\n",
        "\n",
        "Use Case: Suitable for sharing complex data structures between processes, as it allows them to synchronize access to shared objects like lists or dictionaries."
      ],
      "metadata": {
        "id": "M9_Ab9sAt5vG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Manager\n",
        "\n",
        "manager = Manager()\n",
        "shared_list = manager.list()  # A list that can be shared between processes\n",
        "shared_dict = manager.dict()  # A dictionary that can be shared between processes"
      ],
      "metadata": {
        "id": "Kxuo6Q9qt9i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Higher-Level Tools for Data Sharing in Python\n",
        "\n",
        "Concurrent Futures (concurrent.futures)\n",
        "\n",
        "Description: Provides high-level abstractions for both multithreading (ThreadPoolExecutor) and multiprocessing (ProcessPoolExecutor) via a unified API, handling thread and process management.\n",
        "\n",
        "Use Case: Useful for performing parallel tasks without directly managing threads or processes"
      ],
      "metadata": {
        "id": "2Z0mGtrhuArd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    futures = [executor.submit(some_function, arg) for arg in args]"
      ],
      "metadata": {
        "id": "qHNIwDoCuJK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asyncio (asyncio)\n",
        "\n",
        "Description: An asynchronous programming library that provides an event loop for handling I/O-bound tasks concurrently using coroutines, not actual threads or processes.\n",
        "\n",
        "Use Case: Ideal for I/O-bound tasks like network calls, file handling, or user input, where true parallelism is not needed but concurrency improves performance."
      ],
      "metadata": {
        "id": "a0XlAjY2uM49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def async_task():\n",
        "    await asyncio.sleep(1)"
      ],
      "metadata": {
        "id": "aoQmZWaguQ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for\n",
        "doing so**"
      ],
      "metadata": {
        "id": "zsYzKrh3uYDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling exceptions in concurrent programs is crucial because concurrent execution can lead to complex, hard-to-diagnose errors, such as deadlocks, resource leaks, or inconsistent states, especially if exceptions are not properly managed. If one part of a concurrent program encounters an exception and fails without being handled, it can impact other parts of the program, potentially bringing the entire system down."
      ],
      "metadata": {
        "id": "h8Vkk10VudtI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importance of Exception Handling in Concurrent Programs\n",
        "\n",
        "Maintaining Program Stability:\n",
        "\n",
        "\n",
        "Unhandled exceptions can terminate threads or processes abruptly, causing loss of data, incomplete operations, or inconsistencies. For example, if a thread fails while holding a lock, it can cause a deadlock, as other threads will be unable to access the resource.\n",
        "\n",
        "Preventing Resource Leaks:\n",
        "\n",
        "\n",
        "If exceptions are not handled, resources such as memory, files, network connections, or database locks may not be properly released, leading to resource exhaustion.\n",
        "\n",
        "Debugging and Error Diagnosis:\n",
        "\n",
        "Exceptions in concurrent programs are harder to trace because errors may occur simultaneously in multiple threads or processes. Proper handling and logging of exceptions can make it easier to identify the root cause of failures.\n",
        "\n",
        "Ensuring Task Completion or Graceful Failure:\n",
        "\n",
        "In concurrent environments, ensuring that critical tasks complete or fail gracefully is essential. Exception handling helps ensure that essential cleanup is performed and the program state is preserved, even in the event of errors.\n"
      ],
      "metadata": {
        "id": "sOm75t1ruhA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "1. Try-Except Blocks in Threads and Processes\n",
        "\n",
        "Technique: Wrap critical code in a try-except block within each thread or process. This ensures that exceptions are caught and logged or handled locally without affecting other parts of the program."
      ],
      "metadata": {
        "id": "9A1XfmDCvCMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    try:\n",
        "        # Code that may raise an exception\n",
        "        result = 10 / 0  # This will raise a ZeroDivisionError\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception caught in thread: {e}\")\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "fNuE7QyqvG6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Using concurrent.futures for Exception Propagatio\n",
        "\n",
        "Technique: The concurrent.futures module provides a higher-level interface for multithreading and multiprocessing with ThreadPoolExecutor and ProcessPoolExecutor. When a task raises an exception, it is captured and can be retrieved via the Future object, which represents the result of an asynchronous operation."
      ],
      "metadata": {
        "id": "WIYHSPl0vLLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def divide(x, y):\n",
        "    return x / y\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(divide, 10, 0)\n",
        "    try:\n",
        "        result = future.result()  # This will raise a ZeroDivisionError\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Exception caught from future: {e}\")"
      ],
      "metadata": {
        "id": "uZrbAdXdvTA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Using Thread and Process with Exception Logging\n",
        "\n",
        "Technique: Override the run method in a custom Thread or Process class to add exception handling, logging exceptions directly from within the thread or process. This approach is helpful for logging and monitoring errors in long-running or daemon threads."
      ],
      "metadata": {
        "id": "EZAr3JCvvV4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "class CustomThread(threading.Thread):\n",
        "    def run(self):\n",
        "        try:\n",
        "            # Code that may raise an exception\n",
        "            result = 10 / 0\n",
        "        except Exception as e:\n",
        "            print(f\"Exception in thread: {e}\")\n",
        "\n",
        "thread = CustomThread()\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "cJ42yxvuvYwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Using Queues for Error Reporting\n",
        "\n",
        "Technique: For more complex concurrent setups, use a Queue to pass exceptions from threads or processes back to the main thread. This allows the main thread to monitor for errors and respond appropriately, potentially retrying failed tasks or logging errors centrally."
      ],
      "metadata": {
        "id": "fSW0tzlivcQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from queue import Queue\n",
        "import threading\n",
        "\n",
        "def worker(queue):\n",
        "    try:\n",
        "        # Code that may raise an exception\n",
        "        result = 10 / 0\n",
        "    except Exception as e:\n",
        "        queue.put(e)  # Put the exception in the queue for handling\n",
        "\n",
        "error_queue = Queue()\n",
        "thread = threading.Thread(target=worker, args=(error_queue,))\n",
        "thread.start()\n",
        "thread.join()\n",
        "\n",
        "while not error_queue.empty():\n",
        "    error = error_queue.get()\n",
        "    print(f\"Exception from queue: {error}\")"
      ],
      "metadata": {
        "id": "xos8UCv7vfBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Timeouts and Exception Handling in concurrent.futures\n",
        "\n",
        "Technique: Set timeouts on Future.result() or Executor.map() calls to handle cases where tasks are taking too long or are stuck due to an unexpected condition. This is especially useful when tasks involve external dependencies, like network calls, which may hang indefinitely.\n"
      ],
      "metadata": {
        "id": "fXc3UR-kvili"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
        "\n",
        "def long_running_task():\n",
        "    import time\n",
        "    time.sleep(5)  # Simulate long task\n",
        "    return \"Done\"\n",
        "\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    future = executor.submit(long_running_task)\n",
        "    try:\n",
        "        result = future.result(timeout=2)  # Set timeout to 2 seconds\n",
        "    except TimeoutError:\n",
        "        print(\"Task timed out\")"
      ],
      "metadata": {
        "id": "HbuZG3xdvlhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Context Managers for Resource Cleanup\n",
        "\n",
        "Technique: Use context managers (with statements) to ensure that resources are automatically cleaned up even if an exception occurs. This can prevent resource leaks in concurrent programs."
      ],
      "metadata": {
        "id": "POrW8HLZxhT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def worker():\n",
        "    with open(\"data.txt\", \"w\") as f:\n",
        "        f.write(\"Writing data\")  # This file will be properly closed even if an exception occurs\n",
        "\n",
        "thread = threading.Thread(target=worker)\n",
        "thread.start()\n",
        "thread.join()"
      ],
      "metadata": {
        "id": "c7f3JeNtxkeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Custom Exception Handlers in Multiprocessing\n",
        "\n",
        "Technique: In multiprocessing, use an error callback to handle exceptions when submitting tasks with apply_async(). This allows capturing exceptions raised by individual processes and handling them centrally."
      ],
      "metadata": {
        "id": "cMbPWxnDxn5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def worker(x):\n",
        "    return 10 / x\n",
        "\n",
        "def error_callback(e):\n",
        "    print(f\"Exception caught in process: {e}\")\n",
        "\n",
        "with Pool(4) as pool:\n",
        "    pool.apply_async(worker, args=(0,), error_callback=error_callback)  # This will raise a ZeroDivisionError\n",
        "    pool.close()\n",
        "    pool.join()"
      ],
      "metadata": {
        "id": "k9P_RFDsxuoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently.\n",
        "Use concurrent.futures.ThreadPoolExecutor to manage the threads.**"
      ],
      "metadata": {
        "id": "cXqeFX8kxyAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a Python program that uses concurrent.futures.ThreadPoolExecutor to calculate the factorial of numbers from 1 to 10 concurrently. The program creates a thread pool, assigns each factorial calculation to a separate thread, and then retrieves and prints the results."
      ],
      "metadata": {
        "id": "7gihd1Vvx2kO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Function to calculate factorial\n",
        "def factorial(n):\n",
        "    if n == 0 or n == 1:\n",
        "        return 1\n",
        "    result = 1\n",
        "    for i in range(2, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "# Numbers for which we want to calculate factorials\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Using ThreadPoolExecutor to manage the threads\n",
        "with ThreadPoolExecutor() as executor:\n",
        "    # Submit tasks to calculate factorials\n",
        "    futures = {executor.submit(factorial, num): num for num in numbers}\n",
        "\n",
        "    # Retrieve and print results as they complete\n",
        "    for future in as_completed(futures):\n",
        "        number = futures[future]\n",
        "        try:\n",
        "            result = future.result()\n",
        "            print(f\"Factorial of {number} is {result}\")\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while calculating factorial of {number}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3AlN1_2x5oF",
        "outputId": "ea0b19ba-cbee-4ff0-a5e1-a23c697ec205"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 8 is 40320\n",
            "Factorial of 10 is 3628800\n",
            "Factorial of 5 is 120\n",
            "Factorial of 6 is 720\n",
            "Factorial of 1 is 1\n",
            "Factorial of 4 is 24\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 2 is 2\n",
            "Factorial of 3 is 6\n",
            "Factorial of 7 is 5040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in\n",
        "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8\n",
        "processes).**"
      ],
      "metadata": {
        "id": "FvJIwYmVx8e0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here’s a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in parallel. The program measures the time taken for computation with different pool sizes (2, 4, and 8 processes) to compare performance."
      ],
      "metadata": {
        "id": "0juf4ZoIyAIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def square(n):\n",
        "    return n * n\n",
        "\n",
        "# List of numbers to square\n",
        "numbers = list(range(1, 11))\n",
        "\n",
        "# Function to measure computation time with a given pool size\n",
        "def measure_time(pool_size):\n",
        "    start_time = time.time()\n",
        "    with Pool(processes=pool_size) as pool:\n",
        "        results = pool.map(square, numbers)\n",
        "    end_time = time.time()\n",
        "    print(f\"Pool size {pool_size}: Results = {results}, Time taken = {end_time - start_time:.4f} seconds\")\n",
        "\n",
        "# Test with different pool sizes\n",
        "for size in [2, 4, 8]:\n",
        "    measure_time(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glvbWt3oyDRk",
        "outputId": "17bb43d8-e50d-4c16-ce99-b3eca705f817"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size 2: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = 0.0506 seconds\n",
            "Pool size 4: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = 0.0634 seconds\n",
            "Pool size 8: Results = [1, 4, 9, 16, 25, 36, 49, 64, 81, 100], Time taken = 0.1120 seconds\n"
          ]
        }
      ]
    }
  ]
}